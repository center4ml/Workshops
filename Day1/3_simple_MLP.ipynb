{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa309ca0-8167-40d3-8531-f52500c9e23d",
      "metadata": {
        "id": "fa309ca0-8167-40d3-8531-f52500c9e23d"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this workshop, we will dive into a construction of a simple MultiLayer Perceptron neural network. A MultiLayer Perceptron, also termed MLP, is a simple network consisting of a few fully connected linear layers \n",
        "\n",
        "![MLP - image from https://www.researchgate.net/publication/341626283_Prioritizing_and_Analyzing_the_Role_of_Climate_and_Urban_Parameters_in_the_Confirmed_Cases_of_COVID-19_Based_on_Artificial_Intelligence_Applications](https://i.imgur.com/8cw4GD3.png)\n",
        "\n",
        "Linear layers must be separated by nonlinear components (also called *activation functions*). \n",
        "\n",
        "![non-linear components - image from https://www.simplilearn.com/tutorials/deep-learning-tutorial/perceptron](https://imgur.com/L3YxcSs.png)\n",
        "\n",
        "![pencil](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/pencil2.png) \n",
        "### Your task #1\n",
        "\n",
        "What is the purpose of the non-linearities in-between the layers of the neural network?\n",
        "\n",
        "In this workshop, we will construct an MLP network designed to a specific task of classification of MNIST dataset: a set of handwritten digits 0-9. MNIST stands for Modified National Institute of Standards and Technology database.\n",
        "\n",
        "![ledger](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/ledger.png) You can read more about this dataset [here](https://colah.github.io/posts/2014-10-Visualizing-MNIST/#MNIST)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7744bb4a-667d-47dc-b2c8-9bbc797634e3",
      "metadata": {
        "id": "7744bb4a-667d-47dc-b2c8-9bbc797634e3"
      },
      "source": [
        "# Before we begin\n",
        "\n",
        "There is a departure from the neuron-like biological terminology in ANN community. You will see even in this very simple example, that it is more convenient to think of layers not as of data points (neurons) but as of mathematical transformations (so a layer would be a matrix multiplication by weights or a layer would be aplication of nonlinear transform, or both, and in this latter case a layer would decompose further). \n",
        "\n",
        "In the case of more complex networks like Transformers it would be even hard to find a neuron analogy. Transformers explicitly work with matrices and generally with mathematical abstractions.\n",
        "\n",
        "The departure from the neural terminology is also justified by biology, itself. It turns out, that a single neuron in a brain behaves much more like a full artificial neural network than like an artificial neuron. \n",
        "\n",
        "The authors of the paper cited below show that, at the very least, a 5-layer 128-unit TCN — temporal convolutional network — is needed to simulate the I/O patterns of a pyramidal neuron at the millisecond resolution (single spike precision). To make a gross comparison: This means a single biological neuron needs between 640 and 2048 artificial neurons to be simulated adequately.\n",
        "\n",
        "![ledger](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/ledger.png) [Beniaguev D, Segev I, London M. Single cortical neurons as deep artificial neural networks. Neuron. 2021 Sep 1;109(17):2727-2739.e3. doi: 10.1016/j.neuron.2021.07.002](https://pubmed.ncbi.nlm.nih.gov/34380016/)\n",
        "\n",
        "![ledger](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/ledger.png) For the interested reader: [here you can read about Transformers](https://jalammar.github.io/illustrated-transformer/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d6f69064-608d-4e2c-9179-9ff00a3afb4d",
      "metadata": {
        "id": "d6f69064-608d-4e2c-9179-9ff00a3afb4d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e68b3fa0-99e0-490c-ae8c-f2c650c8bf72",
      "metadata": {
        "id": "e68b3fa0-99e0-490c-ae8c-f2c650c8bf72"
      },
      "source": [
        "### Reading MNIST data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a3f72963-c85d-49a6-9297-e14f823acc21",
      "metadata": {
        "id": "a3f72963-c85d-49a6-9297-e14f823acc21",
        "outputId": "60cf81e7-a5dd-4ab0-e522-0e4a7d8426bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "9e7ce9bd32d640a0b42f1ff8392393cd",
            "9d720433201645e58e49476dfc89df4f",
            "1fa86ad8cc524480a75bd21fbd8015f3",
            "eb8f58eae2c8485896ba7eeeb516c540",
            "a8e292933de94bb5a0b1743caea484e9",
            "8f9f3f87db7345a4bc75fc3ff209e546",
            "80eb6ec39ddd48e6b8171f71b327314f",
            "158d6a1af0ce47bf82776473306641a9",
            "5c845ff5b498426eba1fcfd45d38509c",
            "b3a5ea9e3844423590266267c0877618",
            "2b47e8cd73e04131abc85eaf9c37bb3e",
            "240502466e4e4c238309f3f5d61a9449",
            "b1d1046806e74950aa807c06266c9548",
            "4619180ec58541099ce9bcca1af795ab",
            "ae2022cbe08f447489e154f4cf0924ff",
            "30a8a17ed1cc453ea2234529ed918f29",
            "3fd1185e0867499299d1e059570ed74c",
            "1a149ad697784f3ab41ddccdbdf3e4b5",
            "5b3b33aca55842b9a8fcd9507594448a",
            "fe9872aceb1248c79ca2c60ae2152eb6",
            "7ba79ce8ca9f4d62be8d2b883838f526",
            "1a35683699be427cb7e6d85a61e76369",
            "fe7832b129c54e8facfc96b36d490bea",
            "f4e958896a134b0bbac8bcf9922bdad3",
            "579b7b34cb714c8ea7a4ca51b1dd7f45",
            "fa3e8d88776a4ca6865cd28e3d4a56ca",
            "88d9fb6c8d9b41c09d85aae5462f0faa",
            "90a257c64053484b9a1142d95714b8ec",
            "b468736363b24e8394b817238f924f3f",
            "6e7bd542642e44dcb2ac53f6fbe9ee98",
            "ecbe7f1143004f279167da08478ae8ff",
            "b4d67d908fc0423298b9a4c08f73a5cc",
            "c4d0fa5a59464cd290977e94c39a0e67",
            "49ddedd508f34300b9d5e80a99a37849",
            "c820aec5068d420ca41baf7ab5e97141",
            "784194ed3c014b87b75598bb79ea4e33",
            "34d510c44f444b71a867849d8db00780",
            "2de41eab99484a239812c70f8c0120f3",
            "7058d0dcccf144688e05b4cd4157a2db",
            "ae2fe29e3d3f4f5a9d7e834b3b323624",
            "e03dff88b819422c9361b8729b810bff",
            "869a339cc1684ff6a8f32f7b253b6096",
            "7f57aecfa5174e958309bb4946b6046e",
            "b6e9e6eb07764ccd8c39e2a538207339"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e7ce9bd32d640a0b42f1ff8392393cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "240502466e4e4c238309f3f5d61a9449"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe7832b129c54e8facfc96b36d490bea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49ddedd508f34300b9d5e80a99a37849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4ff41560-0ea3-4d94-a7ad-c96eaf8206b0",
      "metadata": {
        "id": "4ff41560-0ea3-4d94-a7ad-c96eaf8206b0",
        "outputId": "0e9a8979-3774-4665-ac79-f6eb498dd777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "train_image, train_target = trainset[0]    #let us examine the 0-th sample\n",
        "pyplot.imshow(train_image)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "06195ef1-534d-45fa-99dd-40ae24b55011",
      "metadata": {
        "id": "06195ef1-534d-45fa-99dd-40ae24b55011",
        "outputId": "be01c1f5-3b19-429e-c5e6-55a7a62c0cad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
              "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
              "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
              "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
              "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
              "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
              "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
              "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
              "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
              "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
              "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
              "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
              "       dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "trainset.data[0]     #it will be shown in two rows, so a human has hard time classificating it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9eb5008e-a4b7-4b26-a08a-674988dc8854",
      "metadata": {
        "id": "9eb5008e-a4b7-4b26-a08a-674988dc8854",
        "outputId": "c50de85e-2b74-4019-b3bb-8ed9f022c8b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_target    #check if you classified it correctly in your mind"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a36d86f-9f32-477b-bd2d-b05eea185f86",
      "metadata": {
        "id": "5a36d86f-9f32-477b-bd2d-b05eea185f86"
      },
      "source": [
        "![pencil](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/pencil2.png) \n",
        "### Your task #2\n",
        "\n",
        "Examine a few more samples from mnist dataset. Try to guess the correct class correctly, classifing images with your human classification skills. Try to estimate the accuracy, i.e. what is your percentage of correct classifications - treating a training set that we are examining now as a test set for you. It is sound, because you have not trained on that set before attempting the classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28199903-bff6-431b-b855-32d37683ef2b",
      "metadata": {
        "id": "28199903-bff6-431b-b855-32d37683ef2b"
      },
      "source": [
        "![pencil](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/pencil2.png) \n",
        "### Your task #3\n",
        "\n",
        "Try to convert the dataset into numpy `ndarray`. Then estimate mean and standard deviation of MNIST dataset. Please remember that it is customary to first divide each value in MNIST dataset by 255, to normalize the initial pixel RGB values 0-255 into (0,1) range.\n",
        "\n",
        "*Tips:* \n",
        "- to convert MNIST dataset to numpy, use `trainset.data.numpy()`\n",
        "- in numpy, there are methods `mean()` and `std()` to calculate statistics of a vector. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0ba5df57-2b6c-44d2-a521-375bd4375f2b",
      "metadata": {
        "id": "0ba5df57-2b6c-44d2-a521-375bd4375f2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "982887f9-f016-4e62-9ee0-0e8415f8dc69",
      "metadata": {
        "id": "982887f9-f016-4e62-9ee0-0e8415f8dc69"
      },
      "source": [
        "Now, we will reread the dataset (**train** and **test** parts) and transform it (standardize it) so it will be zero-mean and unit-std. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5c16a443-c40d-430f-977b-e6749192950e",
      "metadata": {
        "id": "5c16a443-c40d-430f-977b-e6749192950e"
      },
      "outputs": [],
      "source": [
        "transform = torchvision.transforms.Compose(\n",
        "    [ torchvision.transforms.ToTensor(), #Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "      torchvision.transforms.Normalize((0.1307), (0.3081))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=2048, shuffle=True)   #we do shuffle it to give more randomizations to training epochs\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "815882fa-4f93-403a-9221-36bb34649579",
      "metadata": {
        "id": "815882fa-4f93-403a-9221-36bb34649579"
      },
      "source": [
        "Let us visualise the training labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "96d91c90-680e-4b1a-9045-3f8709f1bad9",
      "metadata": {
        "id": "96d91c90-680e-4b1a-9045-3f8709f1bad9",
        "outputId": "4c1eed24-95fe-4e64-e7f7-6d1860542429",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 -th batch labels : tensor([5, 1, 2,  ..., 0, 7, 3])\n",
            "1 -th batch labels : tensor([0, 4, 3,  ..., 1, 4, 7])\n",
            "2 -th batch labels : tensor([1, 5, 7,  ..., 9, 4, 0])\n",
            "3 -th batch labels : tensor([0, 7, 3,  ..., 9, 9, 8])\n",
            "4 -th batch labels : tensor([1, 8, 6,  ..., 5, 9, 0])\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(trainloader):\n",
        "        batch_inputs, batch_labels = data\n",
        "\n",
        "        if i<5:\n",
        "            print(i, \"-th batch labels :\", batch_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad9a5923-85fb-47e7-9136-e1fecd4d38d2",
      "metadata": {
        "id": "ad9a5923-85fb-47e7-9136-e1fecd4d38d2"
      },
      "source": [
        "![pencil](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/pencil2.png) \n",
        "### Your taks #4\n",
        "\n",
        "A single label is an entity of order zero (a constant), but batched labels are of order one. The first (and only) index is a sample index within a batch. \n",
        "\n",
        "Your task is to visualise and inspect the number of orders in data in batch_inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "615a2819-907c-4dd8-9b03-765d5de27885",
      "metadata": {
        "id": "615a2819-907c-4dd8-9b03-765d5de27885"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b75ea4d6-088e-40c8-84d5-354d4a37f168",
      "metadata": {
        "id": "b75ea4d6-088e-40c8-84d5-354d4a37f168"
      },
      "source": [
        "OK, so each data image was initially a two dimensional image when we first saw it, but now the batches have order 4. The first index is a sample index within a batch, but a second index is always 0. This index represents a Channel number inserted here by ToTensor() transformation, always 0. As this order is one-dimensional, we can get rid of it, later, in training, in `Flatten()` layer or by using `squeeze()` on a tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19b73524-9d07-4882-a2b0-3e29233213a8",
      "metadata": {
        "id": "19b73524-9d07-4882-a2b0-3e29233213a8"
      },
      "source": [
        "### MLP\n",
        "\n",
        "Now, a definition of a simple MLP network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "74fb8859-01d0-4b5e-a3e0-f06e77c72a64",
      "metadata": {
        "id": "74fb8859-01d0-4b5e-a3e0-f06e77c72a64"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.mlp = torch.nn.Sequential(   #Sequential is a structure which allows stacking layers one on another in such a way, \n",
        "                                          #that output from a preceding layer serves as input to the next layer \n",
        "            torch.nn.Flatten(),   #change the last three orders in data (with dimensions 1, 28 and 28 respectively) into one order of dimensions (1*28*28)\n",
        "            torch.nn.Linear(1*28*28, 1024),  #which is used as INPUT to the first Linear layer\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(1024, 2048),   #IMPORTANT! Please observe, that the OUTPUT dimension of a preceding layer is always equal to the INPUT dimension of the next layer.\n",
        "            torch.nn.Sigmoid(),\n",
        "            torch.nn.Linear(2048, 256),\n",
        "            torch.nn.Sigmoid(),            #Sigmoid is a nonlinear function which is used in-between layers\n",
        "            torch.nn.Linear(256, 10),\n",
        "        )\n",
        "        self.dropout = torch.nn.Dropout(0.05)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mlp(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fdc9a16-9cd3-40e6-988e-bc783e67833a",
      "metadata": {
        "id": "3fdc9a16-9cd3-40e6-988e-bc783e67833a"
      },
      "source": [
        "### Training\n",
        "\n",
        "Training consists of \n",
        "- an initiation of a network\n",
        "- a definition of an optimizer. Optimizer does a gradient descent on gradients computed in a `backward()` step on a loss.\n",
        "- running through multiple epochs and updating the network weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "58af5c66-1b38-4dec-82c7-44bcd0548d25",
      "metadata": {
        "id": "58af5c66-1b38-4dec-82c7-44bcd0548d25",
        "outputId": "dfa35daf-e58d-4a32-cf41-163a6f3ef5c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 batch: 0 current batch loss: 2.327420949935913\n",
            "epoch: 0 batch: 1 current batch loss: 2.4023232460021973\n",
            "epoch: 0 batch: 2 current batch loss: 2.351797580718994\n",
            "epoch: 0 batch: 3 current batch loss: 2.315108299255371\n",
            "epoch: 0 batch: 4 current batch loss: 2.279952049255371\n",
            "epoch: 0 batch: 5 current batch loss: 2.2681941986083984\n",
            "epoch: 0 batch: 6 current batch loss: 2.2635600566864014\n",
            "epoch: 0 batch: 7 current batch loss: 2.233426094055176\n",
            "epoch: 0 batch: 8 current batch loss: 2.1982169151306152\n",
            "epoch: 0 batch: 9 current batch loss: 2.134267807006836\n",
            "epoch: 0 batch: 10 current batch loss: 2.0787363052368164\n",
            "epoch: 0 batch: 11 current batch loss: 2.0027310848236084\n",
            "epoch: 0 batch: 12 current batch loss: 1.9239039421081543\n",
            "epoch: 0 batch: 13 current batch loss: 1.819178581237793\n",
            "epoch: 0 batch: 14 current batch loss: 1.7238916158676147\n",
            "epoch: 0 batch: 15 current batch loss: 1.6340073347091675\n",
            "epoch: 0 batch: 16 current batch loss: 1.5430880784988403\n",
            "epoch: 0 batch: 17 current batch loss: 1.4909793138504028\n",
            "epoch: 0 batch: 18 current batch loss: 1.4059011936187744\n",
            "epoch: 0 batch: 19 current batch loss: 1.3434371948242188\n",
            "epoch: 0 batch: 20 current batch loss: 1.272508978843689\n",
            "epoch: 0 batch: 21 current batch loss: 1.2592488527297974\n",
            "epoch: 0 batch: 22 current batch loss: 1.2061220407485962\n",
            "epoch: 0 batch: 23 current batch loss: 1.1551555395126343\n",
            "epoch: 0 batch: 24 current batch loss: 1.0957647562026978\n",
            "epoch: 0 batch: 25 current batch loss: 1.0789241790771484\n",
            "epoch: 0 batch: 26 current batch loss: 1.0339410305023193\n",
            "epoch: 0 batch: 27 current batch loss: 1.033150553703308\n",
            "epoch: 0 batch: 28 current batch loss: 0.9798274636268616\n",
            "epoch: 0 batch: 29 current batch loss: 0.9133623242378235\n",
            "epoch: 1 batch: 0 current batch loss: 0.9242231249809265\n",
            "epoch: 1 batch: 1 current batch loss: 0.898408830165863\n",
            "epoch: 1 batch: 2 current batch loss: 0.8546279668807983\n",
            "epoch: 1 batch: 3 current batch loss: 0.8191330432891846\n",
            "epoch: 1 batch: 4 current batch loss: 0.7912152409553528\n",
            "epoch: 1 batch: 5 current batch loss: 0.7994136214256287\n",
            "epoch: 1 batch: 6 current batch loss: 0.752292811870575\n",
            "epoch: 1 batch: 7 current batch loss: 0.7395505905151367\n",
            "epoch: 1 batch: 8 current batch loss: 0.7136583924293518\n",
            "epoch: 1 batch: 9 current batch loss: 0.6932308077812195\n",
            "epoch: 1 batch: 10 current batch loss: 0.6842530369758606\n",
            "epoch: 1 batch: 11 current batch loss: 0.6829079985618591\n",
            "epoch: 1 batch: 12 current batch loss: 0.6279652714729309\n",
            "epoch: 1 batch: 13 current batch loss: 0.6103829741477966\n",
            "epoch: 1 batch: 14 current batch loss: 0.5948972105979919\n",
            "epoch: 1 batch: 15 current batch loss: 0.5918101072311401\n",
            "epoch: 1 batch: 16 current batch loss: 0.5893596410751343\n",
            "epoch: 1 batch: 17 current batch loss: 0.6043869853019714\n",
            "epoch: 1 batch: 18 current batch loss: 0.5558373332023621\n",
            "epoch: 1 batch: 19 current batch loss: 0.5858647227287292\n",
            "epoch: 1 batch: 20 current batch loss: 0.48297274112701416\n",
            "epoch: 1 batch: 21 current batch loss: 0.5095986127853394\n",
            "epoch: 1 batch: 22 current batch loss: 0.4904814660549164\n",
            "epoch: 1 batch: 23 current batch loss: 0.49743369221687317\n",
            "epoch: 1 batch: 24 current batch loss: 0.5037941336631775\n",
            "epoch: 1 batch: 25 current batch loss: 0.48216545581817627\n",
            "epoch: 1 batch: 26 current batch loss: 0.4566377103328705\n",
            "epoch: 1 batch: 27 current batch loss: 0.47411513328552246\n",
            "epoch: 1 batch: 28 current batch loss: 0.4475758373737335\n",
            "epoch: 1 batch: 29 current batch loss: 0.47845056653022766\n",
            "epoch: 2 batch: 0 current batch loss: 0.4420633316040039\n",
            "epoch: 2 batch: 1 current batch loss: 0.43446075916290283\n",
            "epoch: 2 batch: 2 current batch loss: 0.4132850170135498\n",
            "epoch: 2 batch: 3 current batch loss: 0.4144403636455536\n",
            "epoch: 2 batch: 4 current batch loss: 0.4107666611671448\n",
            "epoch: 2 batch: 5 current batch loss: 0.44234615564346313\n",
            "epoch: 2 batch: 6 current batch loss: 0.395729660987854\n",
            "epoch: 2 batch: 7 current batch loss: 0.4225883483886719\n",
            "epoch: 2 batch: 8 current batch loss: 0.3940331041812897\n",
            "epoch: 2 batch: 9 current batch loss: 0.3773146867752075\n",
            "epoch: 2 batch: 10 current batch loss: 0.3939560651779175\n",
            "epoch: 2 batch: 11 current batch loss: 0.33990609645843506\n",
            "epoch: 2 batch: 12 current batch loss: 0.3849169611930847\n",
            "epoch: 2 batch: 13 current batch loss: 0.391185998916626\n",
            "epoch: 2 batch: 14 current batch loss: 0.3726588487625122\n",
            "epoch: 2 batch: 15 current batch loss: 0.3980298340320587\n",
            "epoch: 2 batch: 16 current batch loss: 0.36051589250564575\n",
            "epoch: 2 batch: 17 current batch loss: 0.3583518862724304\n",
            "epoch: 2 batch: 18 current batch loss: 0.36247190833091736\n",
            "epoch: 2 batch: 19 current batch loss: 0.39017537236213684\n",
            "epoch: 2 batch: 20 current batch loss: 0.3673413395881653\n",
            "epoch: 2 batch: 21 current batch loss: 0.38008734583854675\n",
            "epoch: 2 batch: 22 current batch loss: 0.3321384787559509\n",
            "epoch: 2 batch: 23 current batch loss: 0.3435812294483185\n",
            "epoch: 2 batch: 24 current batch loss: 0.32042157649993896\n",
            "epoch: 2 batch: 25 current batch loss: 0.3308274745941162\n",
            "epoch: 2 batch: 26 current batch loss: 0.32260411977767944\n",
            "epoch: 2 batch: 27 current batch loss: 0.32721593976020813\n",
            "epoch: 2 batch: 28 current batch loss: 0.3546135723590851\n",
            "epoch: 2 batch: 29 current batch loss: 0.3412679135799408\n",
            "epoch: 3 batch: 0 current batch loss: 0.3072144091129303\n",
            "epoch: 3 batch: 1 current batch loss: 0.3519287705421448\n",
            "epoch: 3 batch: 2 current batch loss: 0.32255885004997253\n",
            "epoch: 3 batch: 3 current batch loss: 0.3420200049877167\n",
            "epoch: 3 batch: 4 current batch loss: 0.320356547832489\n",
            "epoch: 3 batch: 5 current batch loss: 0.3158613443374634\n",
            "epoch: 3 batch: 6 current batch loss: 0.3071887493133545\n",
            "epoch: 3 batch: 7 current batch loss: 0.30013471841812134\n",
            "epoch: 3 batch: 8 current batch loss: 0.276094526052475\n",
            "epoch: 3 batch: 9 current batch loss: 0.28428584337234497\n",
            "epoch: 3 batch: 10 current batch loss: 0.2699476182460785\n",
            "epoch: 3 batch: 11 current batch loss: 0.2677570879459381\n",
            "epoch: 3 batch: 12 current batch loss: 0.26711368560791016\n",
            "epoch: 3 batch: 13 current batch loss: 0.2890622019767761\n",
            "epoch: 3 batch: 14 current batch loss: 0.2726118564605713\n",
            "epoch: 3 batch: 15 current batch loss: 0.27931660413742065\n",
            "epoch: 3 batch: 16 current batch loss: 0.28433069586753845\n",
            "epoch: 3 batch: 17 current batch loss: 0.25230327248573303\n",
            "epoch: 3 batch: 18 current batch loss: 0.2598778009414673\n",
            "epoch: 3 batch: 19 current batch loss: 0.23454567790031433\n",
            "epoch: 3 batch: 20 current batch loss: 0.30220672488212585\n",
            "epoch: 3 batch: 21 current batch loss: 0.27648448944091797\n",
            "epoch: 3 batch: 22 current batch loss: 0.26823651790618896\n",
            "epoch: 3 batch: 23 current batch loss: 0.261363685131073\n",
            "epoch: 3 batch: 24 current batch loss: 0.28503793478012085\n",
            "epoch: 3 batch: 25 current batch loss: 0.2518939971923828\n",
            "epoch: 3 batch: 26 current batch loss: 0.25017619132995605\n",
            "epoch: 3 batch: 27 current batch loss: 0.2818562388420105\n",
            "epoch: 3 batch: 28 current batch loss: 0.2549995481967926\n",
            "epoch: 3 batch: 29 current batch loss: 0.26083722710609436\n",
            "epoch: 4 batch: 0 current batch loss: 0.24286049604415894\n",
            "epoch: 4 batch: 1 current batch loss: 0.23943974077701569\n",
            "epoch: 4 batch: 2 current batch loss: 0.2484995573759079\n",
            "epoch: 4 batch: 3 current batch loss: 0.2309921681880951\n",
            "epoch: 4 batch: 4 current batch loss: 0.2356855571269989\n",
            "epoch: 4 batch: 5 current batch loss: 0.2420138567686081\n",
            "epoch: 4 batch: 6 current batch loss: 0.24255189299583435\n",
            "epoch: 4 batch: 7 current batch loss: 0.22651004791259766\n",
            "epoch: 4 batch: 8 current batch loss: 0.24597984552383423\n",
            "epoch: 4 batch: 9 current batch loss: 0.23247195780277252\n",
            "epoch: 4 batch: 10 current batch loss: 0.21423298120498657\n",
            "epoch: 4 batch: 11 current batch loss: 0.2578642964363098\n",
            "epoch: 4 batch: 12 current batch loss: 0.23029957711696625\n",
            "epoch: 4 batch: 13 current batch loss: 0.2334548830986023\n",
            "epoch: 4 batch: 14 current batch loss: 0.212917298078537\n",
            "epoch: 4 batch: 15 current batch loss: 0.22919665277004242\n",
            "epoch: 4 batch: 16 current batch loss: 0.2248229682445526\n",
            "epoch: 4 batch: 17 current batch loss: 0.20907346904277802\n",
            "epoch: 4 batch: 18 current batch loss: 0.22031769156455994\n",
            "epoch: 4 batch: 19 current batch loss: 0.22967761754989624\n",
            "epoch: 4 batch: 20 current batch loss: 0.21578051149845123\n",
            "epoch: 4 batch: 21 current batch loss: 0.1936035305261612\n",
            "epoch: 4 batch: 22 current batch loss: 0.21621836721897125\n",
            "epoch: 4 batch: 23 current batch loss: 0.21325896680355072\n",
            "epoch: 4 batch: 24 current batch loss: 0.20789901912212372\n",
            "epoch: 4 batch: 25 current batch loss: 0.20772723853588104\n",
            "epoch: 4 batch: 26 current batch loss: 0.20948533713817596\n",
            "epoch: 4 batch: 27 current batch loss: 0.19613154232501984\n",
            "epoch: 4 batch: 28 current batch loss: 0.21306541562080383\n",
            "epoch: 4 batch: 29 current batch loss: 0.20915886759757996\n",
            "epoch: 5 batch: 0 current batch loss: 0.1847716122865677\n",
            "epoch: 5 batch: 1 current batch loss: 0.20525409281253815\n",
            "epoch: 5 batch: 2 current batch loss: 0.1801656186580658\n",
            "epoch: 5 batch: 3 current batch loss: 0.20324589312076569\n",
            "epoch: 5 batch: 4 current batch loss: 0.20681090652942657\n",
            "epoch: 5 batch: 5 current batch loss: 0.18422220647335052\n",
            "epoch: 5 batch: 6 current batch loss: 0.20621506869792938\n",
            "epoch: 5 batch: 7 current batch loss: 0.18257133662700653\n",
            "epoch: 5 batch: 8 current batch loss: 0.19214996695518494\n",
            "epoch: 5 batch: 9 current batch loss: 0.21798308193683624\n",
            "epoch: 5 batch: 10 current batch loss: 0.16798968613147736\n",
            "epoch: 5 batch: 11 current batch loss: 0.1870892494916916\n",
            "epoch: 5 batch: 12 current batch loss: 0.1925288289785385\n",
            "epoch: 5 batch: 13 current batch loss: 0.17913545668125153\n",
            "epoch: 5 batch: 14 current batch loss: 0.20341399312019348\n",
            "epoch: 5 batch: 15 current batch loss: 0.1936609297990799\n",
            "epoch: 5 batch: 16 current batch loss: 0.18899059295654297\n",
            "epoch: 5 batch: 17 current batch loss: 0.181935653090477\n",
            "epoch: 5 batch: 18 current batch loss: 0.19884538650512695\n",
            "epoch: 5 batch: 19 current batch loss: 0.1686272770166397\n",
            "epoch: 5 batch: 20 current batch loss: 0.19279389083385468\n",
            "epoch: 5 batch: 21 current batch loss: 0.1872086226940155\n",
            "epoch: 5 batch: 22 current batch loss: 0.16130483150482178\n",
            "epoch: 5 batch: 23 current batch loss: 0.16261737048625946\n",
            "epoch: 5 batch: 24 current batch loss: 0.16581258177757263\n",
            "epoch: 5 batch: 25 current batch loss: 0.1736280471086502\n",
            "epoch: 5 batch: 26 current batch loss: 0.14771640300750732\n",
            "epoch: 5 batch: 27 current batch loss: 0.17107045650482178\n",
            "epoch: 5 batch: 28 current batch loss: 0.17714066803455353\n",
            "epoch: 5 batch: 29 current batch loss: 0.19942054152488708\n",
            "epoch: 6 batch: 0 current batch loss: 0.16411711275577545\n",
            "epoch: 6 batch: 1 current batch loss: 0.17098468542099\n",
            "epoch: 6 batch: 2 current batch loss: 0.13756635785102844\n",
            "epoch: 6 batch: 3 current batch loss: 0.1686493456363678\n",
            "epoch: 6 batch: 4 current batch loss: 0.17682260274887085\n",
            "epoch: 6 batch: 5 current batch loss: 0.15013687312602997\n",
            "epoch: 6 batch: 6 current batch loss: 0.14273987710475922\n",
            "epoch: 6 batch: 7 current batch loss: 0.16460317373275757\n",
            "epoch: 6 batch: 8 current batch loss: 0.1670791059732437\n",
            "epoch: 6 batch: 9 current batch loss: 0.14786624908447266\n",
            "epoch: 6 batch: 10 current batch loss: 0.15100832283496857\n",
            "epoch: 6 batch: 11 current batch loss: 0.17306669056415558\n",
            "epoch: 6 batch: 12 current batch loss: 0.14932842552661896\n",
            "epoch: 6 batch: 13 current batch loss: 0.15889987349510193\n",
            "epoch: 6 batch: 14 current batch loss: 0.16102339327335358\n",
            "epoch: 6 batch: 15 current batch loss: 0.14957545697689056\n",
            "epoch: 6 batch: 16 current batch loss: 0.1388695240020752\n",
            "epoch: 6 batch: 17 current batch loss: 0.1617339700460434\n",
            "epoch: 6 batch: 18 current batch loss: 0.17171195149421692\n",
            "epoch: 6 batch: 19 current batch loss: 0.13969109952449799\n",
            "epoch: 6 batch: 20 current batch loss: 0.1643502414226532\n",
            "epoch: 6 batch: 21 current batch loss: 0.13928771018981934\n",
            "epoch: 6 batch: 22 current batch loss: 0.14331965148448944\n",
            "epoch: 6 batch: 23 current batch loss: 0.15267568826675415\n",
            "epoch: 6 batch: 24 current batch loss: 0.1449688822031021\n",
            "epoch: 6 batch: 25 current batch loss: 0.1462784856557846\n",
            "epoch: 6 batch: 26 current batch loss: 0.17298360168933868\n",
            "epoch: 6 batch: 27 current batch loss: 0.1671624779701233\n",
            "epoch: 6 batch: 28 current batch loss: 0.16481563448905945\n",
            "epoch: 6 batch: 29 current batch loss: 0.12632128596305847\n",
            "epoch: 7 batch: 0 current batch loss: 0.14218488335609436\n",
            "epoch: 7 batch: 1 current batch loss: 0.12733601033687592\n",
            "epoch: 7 batch: 2 current batch loss: 0.1375955492258072\n",
            "epoch: 7 batch: 3 current batch loss: 0.14550697803497314\n",
            "epoch: 7 batch: 4 current batch loss: 0.1381811648607254\n",
            "epoch: 7 batch: 5 current batch loss: 0.14767462015151978\n",
            "epoch: 7 batch: 6 current batch loss: 0.12572848796844482\n",
            "epoch: 7 batch: 7 current batch loss: 0.15241152048110962\n",
            "epoch: 7 batch: 8 current batch loss: 0.123484767973423\n",
            "epoch: 7 batch: 9 current batch loss: 0.13417305052280426\n",
            "epoch: 7 batch: 10 current batch loss: 0.1376674771308899\n",
            "epoch: 7 batch: 11 current batch loss: 0.12656721472740173\n",
            "epoch: 7 batch: 12 current batch loss: 0.12994329631328583\n",
            "epoch: 7 batch: 13 current batch loss: 0.14299625158309937\n",
            "epoch: 7 batch: 14 current batch loss: 0.13141265511512756\n",
            "epoch: 7 batch: 15 current batch loss: 0.13775020837783813\n",
            "epoch: 7 batch: 16 current batch loss: 0.12139745056629181\n",
            "epoch: 7 batch: 17 current batch loss: 0.13269846141338348\n",
            "epoch: 7 batch: 18 current batch loss: 0.13258858025074005\n",
            "epoch: 7 batch: 19 current batch loss: 0.12346918880939484\n",
            "epoch: 7 batch: 20 current batch loss: 0.14206604659557343\n",
            "epoch: 7 batch: 21 current batch loss: 0.1529226452112198\n",
            "epoch: 7 batch: 22 current batch loss: 0.1309458464384079\n",
            "epoch: 7 batch: 23 current batch loss: 0.14255739748477936\n",
            "epoch: 7 batch: 24 current batch loss: 0.12609811127185822\n",
            "epoch: 7 batch: 25 current batch loss: 0.13352574408054352\n",
            "epoch: 7 batch: 26 current batch loss: 0.11785711348056793\n",
            "epoch: 7 batch: 27 current batch loss: 0.1241813525557518\n",
            "epoch: 7 batch: 28 current batch loss: 0.13117550313472748\n",
            "epoch: 7 batch: 29 current batch loss: 0.1307913213968277\n"
          ]
        }
      ],
      "source": [
        "net = MLP()\n",
        "optimizer = torch.optim.Adam(net.parameters(), 0.001)   #initial and fixed learning rate of 0.001. We will be using ADAM optimizer throughout the workshop\n",
        "                                                        #different choices are possible, but this is outside the scope of this workshop\n",
        "\n",
        "net.train()    #it notifies the network layers (especially batchnorm or dropout layers, which we don't use in this example) that we are doing traning\n",
        "for epoch in range(8):  #  an epoch is a training run through the whole data set\n",
        "\n",
        "    loss = 0.0\n",
        "    for batch, data in enumerate(trainloader):\n",
        "        batch_inputs, batch_labels = data\n",
        "        #batch_inputs.squeeze(1)     #alternatively if not for a Flatten layer, squeeze() could be used to remove the second order of the tensor, the Channel, which is one-dimensional (this index can be equal to 0 only)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_outputs = net(batch_inputs)   #this line calls the forward(self, x) method of the MLP object. Please note, that the last layer of the MLP is linear \n",
        "                                            #and MLP doesn't apply \n",
        "                                            #the nonlinear activation after the last layer\n",
        "        loss = torch.nn.functional.cross_entropy(batch_outputs, batch_labels, reduction = \"mean\") #instead, nonlinear softmax is applied internally in THIS loss function\n",
        "        print(\"epoch:\", epoch, \"batch:\", batch, \"current batch loss:\", loss.item()) \n",
        "        loss.backward()       #this computes gradients as we have seen in previous workshops\n",
        "        optimizer.step()     #but this line in fact updates our neural network. \n",
        "                                ####You can experiment - comment this line and check, that the loss DOES NOT improve, meaning that the network doesn't update\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99335717-7fdf-4335-a8e4-5bd0c30f60e8",
      "metadata": {
        "id": "99335717-7fdf-4335-a8e4-5bd0c30f60e8"
      },
      "source": [
        "![pencil](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/pencil2.png) \n",
        "### Your task #5\n",
        "\n",
        "Comment the line `optimizer.step()` above. Rerun the above code. Note that the loss is NOT constant as the comment in the code seems to promise, but anyway, the loss doesn't improve, either. Please explain, why the loss is not constant. Please explain, why the loss doesn't improve, either.\n",
        "\n",
        "An epoch is a one full passage through the whole training data. Why then, on the second epoch, the losses are different than in the first epoch?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef0ebc3-16fd-4dfd-b4d2-eac9601a4141",
      "metadata": {
        "id": "6ef0ebc3-16fd-4dfd-b4d2-eac9601a4141"
      },
      "source": [
        "### Training - the second approach\n",
        "\n",
        "\n",
        "Sometimes during training loss stabilizes and doesn't improve anymore. It is not the case here (yet, but we have only run 8 epochs), but a real problem in practice.\n",
        "We can include a new tool called a **scheduler** that would update the *learning rate* in an otpimizer after each epoch. This usually helps the training. Let us reformulate the traning so it consists of \n",
        "- an initiation of a network\n",
        "- a definition of an optimizer. Optimizer does a gradient descent on gradients computed in a `backward()` step on a loss.\n",
        "- a definition of a scheduler to update the learning rate in an optimizer\n",
        "- running through multiple epochs and updating the network weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8a9e98b1-a2aa-4af6-b037-0f5e1352dddc",
      "metadata": {
        "id": "8a9e98b1-a2aa-4af6-b037-0f5e1352dddc",
        "outputId": "8dd15caf-6f61-4dbd-e1d8-ea991a2b2484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 batch: 0 current batch loss: 2.3302512168884277 current lr: 0.001\n",
            "epoch: 0 batch: 1 current batch loss: 2.4167819023132324 current lr: 0.001\n",
            "epoch: 0 batch: 2 current batch loss: 2.38674259185791 current lr: 0.001\n",
            "epoch: 0 batch: 3 current batch loss: 2.300973892211914 current lr: 0.001\n",
            "epoch: 0 batch: 4 current batch loss: 2.2797157764434814 current lr: 0.001\n",
            "epoch: 0 batch: 5 current batch loss: 2.2805354595184326 current lr: 0.001\n",
            "epoch: 0 batch: 6 current batch loss: 2.2808778285980225 current lr: 0.001\n",
            "epoch: 0 batch: 7 current batch loss: 2.256521701812744 current lr: 0.001\n",
            "epoch: 0 batch: 8 current batch loss: 2.209502935409546 current lr: 0.001\n",
            "epoch: 0 batch: 9 current batch loss: 2.15400767326355 current lr: 0.001\n",
            "epoch: 0 batch: 10 current batch loss: 2.085397243499756 current lr: 0.001\n",
            "epoch: 0 batch: 11 current batch loss: 2.0302412509918213 current lr: 0.001\n",
            "epoch: 0 batch: 12 current batch loss: 1.9630849361419678 current lr: 0.001\n",
            "epoch: 0 batch: 13 current batch loss: 1.8931758403778076 current lr: 0.001\n",
            "epoch: 0 batch: 14 current batch loss: 1.8201695680618286 current lr: 0.001\n",
            "epoch: 0 batch: 15 current batch loss: 1.7657970190048218 current lr: 0.001\n",
            "epoch: 0 batch: 16 current batch loss: 1.6500211954116821 current lr: 0.001\n",
            "epoch: 0 batch: 17 current batch loss: 1.576697826385498 current lr: 0.001\n",
            "epoch: 0 batch: 18 current batch loss: 1.512753963470459 current lr: 0.001\n",
            "epoch: 0 batch: 19 current batch loss: 1.4518194198608398 current lr: 0.001\n",
            "epoch: 0 batch: 20 current batch loss: 1.4125709533691406 current lr: 0.001\n",
            "epoch: 0 batch: 21 current batch loss: 1.3515212535858154 current lr: 0.001\n",
            "epoch: 0 batch: 22 current batch loss: 1.3006255626678467 current lr: 0.001\n",
            "epoch: 0 batch: 23 current batch loss: 1.2718366384506226 current lr: 0.001\n",
            "epoch: 0 batch: 24 current batch loss: 1.1922036409378052 current lr: 0.001\n",
            "epoch: 0 batch: 25 current batch loss: 1.1755512952804565 current lr: 0.001\n",
            "epoch: 0 batch: 26 current batch loss: 1.1212488412857056 current lr: 0.001\n",
            "epoch: 0 batch: 27 current batch loss: 1.0750850439071655 current lr: 0.001\n",
            "epoch: 0 batch: 28 current batch loss: 1.0455467700958252 current lr: 0.001\n",
            "epoch: 0 batch: 29 current batch loss: 1.015842080116272 current lr: 0.001\n",
            "epoch: 1 batch: 0 current batch loss: 0.991044282913208 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 1 current batch loss: 0.9648186564445496 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 2 current batch loss: 0.9241276383399963 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 3 current batch loss: 0.9418290853500366 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 4 current batch loss: 0.9041574001312256 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 5 current batch loss: 0.8632700443267822 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 6 current batch loss: 0.8185272216796875 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 7 current batch loss: 0.8266640901565552 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 8 current batch loss: 0.7818058729171753 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 9 current batch loss: 0.8026789426803589 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 10 current batch loss: 0.7325398325920105 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 11 current batch loss: 0.7635988593101501 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 12 current batch loss: 0.7255117297172546 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 13 current batch loss: 0.6934177279472351 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 14 current batch loss: 0.6772280931472778 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 15 current batch loss: 0.6963798403739929 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 16 current batch loss: 0.6489681005477905 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 17 current batch loss: 0.6619116067886353 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 18 current batch loss: 0.6244786381721497 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 19 current batch loss: 0.6087613105773926 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 20 current batch loss: 0.6441112756729126 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 21 current batch loss: 0.5815213918685913 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 22 current batch loss: 0.5831805467605591 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 23 current batch loss: 0.5843874216079712 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 24 current batch loss: 0.5963438153266907 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 25 current batch loss: 0.556943416595459 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 26 current batch loss: 0.5312276482582092 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 27 current batch loss: 0.5050629377365112 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 28 current batch loss: 0.5211634635925293 current lr: 0.0009000000000000001\n",
            "epoch: 1 batch: 29 current batch loss: 0.49287912249565125 current lr: 0.0009000000000000001\n",
            "epoch: 2 batch: 0 current batch loss: 0.5208994746208191 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 1 current batch loss: 0.4676353633403778 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 2 current batch loss: 0.49582818150520325 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 3 current batch loss: 0.4904128313064575 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 4 current batch loss: 0.4953116178512573 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 5 current batch loss: 0.4760975241661072 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 6 current batch loss: 0.4680861234664917 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 7 current batch loss: 0.45138126611709595 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 8 current batch loss: 0.4426332116127014 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 9 current batch loss: 0.4512145519256592 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 10 current batch loss: 0.43223097920417786 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 11 current batch loss: 0.45129483938217163 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 12 current batch loss: 0.40767428278923035 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 13 current batch loss: 0.40538814663887024 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 14 current batch loss: 0.4224381446838379 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 15 current batch loss: 0.41151702404022217 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 16 current batch loss: 0.42281633615493774 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 17 current batch loss: 0.4201700985431671 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 18 current batch loss: 0.4112011194229126 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 19 current batch loss: 0.39104288816452026 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 20 current batch loss: 0.4008447229862213 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 21 current batch loss: 0.3788570761680603 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 22 current batch loss: 0.39116883277893066 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 23 current batch loss: 0.3630593419075012 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 24 current batch loss: 0.38903141021728516 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 25 current batch loss: 0.37057363986968994 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 26 current batch loss: 0.3724861443042755 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 27 current batch loss: 0.3715250492095947 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 28 current batch loss: 0.36148253083229065 current lr: 0.0008100000000000001\n",
            "epoch: 2 batch: 29 current batch loss: 0.35712894797325134 current lr: 0.0008100000000000001\n",
            "epoch: 3 batch: 0 current batch loss: 0.3373704254627228 current lr: 0.000729\n",
            "epoch: 3 batch: 1 current batch loss: 0.3603443205356598 current lr: 0.000729\n",
            "epoch: 3 batch: 2 current batch loss: 0.35569873452186584 current lr: 0.000729\n",
            "epoch: 3 batch: 3 current batch loss: 0.339105486869812 current lr: 0.000729\n",
            "epoch: 3 batch: 4 current batch loss: 0.37596970796585083 current lr: 0.000729\n",
            "epoch: 3 batch: 5 current batch loss: 0.34295475482940674 current lr: 0.000729\n",
            "epoch: 3 batch: 6 current batch loss: 0.3559721112251282 current lr: 0.000729\n",
            "epoch: 3 batch: 7 current batch loss: 0.30441194772720337 current lr: 0.000729\n",
            "epoch: 3 batch: 8 current batch loss: 0.3333597779273987 current lr: 0.000729\n",
            "epoch: 3 batch: 9 current batch loss: 0.33064699172973633 current lr: 0.000729\n",
            "epoch: 3 batch: 10 current batch loss: 0.3612876236438751 current lr: 0.000729\n",
            "epoch: 3 batch: 11 current batch loss: 0.3215675354003906 current lr: 0.000729\n",
            "epoch: 3 batch: 12 current batch loss: 0.3551495373249054 current lr: 0.000729\n",
            "epoch: 3 batch: 13 current batch loss: 0.3223963677883148 current lr: 0.000729\n",
            "epoch: 3 batch: 14 current batch loss: 0.313266783952713 current lr: 0.000729\n",
            "epoch: 3 batch: 15 current batch loss: 0.3017173111438751 current lr: 0.000729\n",
            "epoch: 3 batch: 16 current batch loss: 0.31595760583877563 current lr: 0.000729\n",
            "epoch: 3 batch: 17 current batch loss: 0.31323808431625366 current lr: 0.000729\n",
            "epoch: 3 batch: 18 current batch loss: 0.3195039629936218 current lr: 0.000729\n",
            "epoch: 3 batch: 19 current batch loss: 0.3056550920009613 current lr: 0.000729\n",
            "epoch: 3 batch: 20 current batch loss: 0.2821597754955292 current lr: 0.000729\n",
            "epoch: 3 batch: 21 current batch loss: 0.29981866478919983 current lr: 0.000729\n",
            "epoch: 3 batch: 22 current batch loss: 0.28129199147224426 current lr: 0.000729\n",
            "epoch: 3 batch: 23 current batch loss: 0.2826009690761566 current lr: 0.000729\n",
            "epoch: 3 batch: 24 current batch loss: 0.30591729283332825 current lr: 0.000729\n",
            "epoch: 3 batch: 25 current batch loss: 0.29972100257873535 current lr: 0.000729\n",
            "epoch: 3 batch: 26 current batch loss: 0.3025117814540863 current lr: 0.000729\n",
            "epoch: 3 batch: 27 current batch loss: 0.2996712625026703 current lr: 0.000729\n",
            "epoch: 3 batch: 28 current batch loss: 0.308210551738739 current lr: 0.000729\n",
            "epoch: 3 batch: 29 current batch loss: 0.27941906452178955 current lr: 0.000729\n",
            "epoch: 4 batch: 0 current batch loss: 0.28358739614486694 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 1 current batch loss: 0.27456778287887573 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 2 current batch loss: 0.2848251461982727 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 3 current batch loss: 0.29828792810440063 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 4 current batch loss: 0.2547135353088379 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 5 current batch loss: 0.2738220691680908 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 6 current batch loss: 0.2573562264442444 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 7 current batch loss: 0.2791309952735901 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 8 current batch loss: 0.2735697031021118 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 9 current batch loss: 0.28360825777053833 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 10 current batch loss: 0.2563539147377014 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 11 current batch loss: 0.27033111453056335 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 12 current batch loss: 0.2692752778530121 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 13 current batch loss: 0.27361971139907837 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 14 current batch loss: 0.26218605041503906 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 15 current batch loss: 0.25393739342689514 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 16 current batch loss: 0.2642291486263275 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 17 current batch loss: 0.2730013132095337 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 18 current batch loss: 0.23709872364997864 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 19 current batch loss: 0.23871618509292603 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 20 current batch loss: 0.2402219921350479 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 21 current batch loss: 0.22284862399101257 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 22 current batch loss: 0.26440486311912537 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 23 current batch loss: 0.2196570336818695 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 24 current batch loss: 0.24676313996315002 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 25 current batch loss: 0.23134246468544006 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 26 current batch loss: 0.23483896255493164 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 27 current batch loss: 0.2536957561969757 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 28 current batch loss: 0.2759120464324951 current lr: 0.0006561000000000001\n",
            "epoch: 4 batch: 29 current batch loss: 0.21811942756175995 current lr: 0.0006561000000000001\n",
            "epoch: 5 batch: 0 current batch loss: 0.24647864699363708 current lr: 0.00059049\n",
            "epoch: 5 batch: 1 current batch loss: 0.23344814777374268 current lr: 0.00059049\n",
            "epoch: 5 batch: 2 current batch loss: 0.23731346428394318 current lr: 0.00059049\n",
            "epoch: 5 batch: 3 current batch loss: 0.2363414317369461 current lr: 0.00059049\n",
            "epoch: 5 batch: 4 current batch loss: 0.20766215026378632 current lr: 0.00059049\n",
            "epoch: 5 batch: 5 current batch loss: 0.22153602540493011 current lr: 0.00059049\n",
            "epoch: 5 batch: 6 current batch loss: 0.255374550819397 current lr: 0.00059049\n",
            "epoch: 5 batch: 7 current batch loss: 0.21199320256710052 current lr: 0.00059049\n",
            "epoch: 5 batch: 8 current batch loss: 0.22118298709392548 current lr: 0.00059049\n",
            "epoch: 5 batch: 9 current batch loss: 0.21812249720096588 current lr: 0.00059049\n",
            "epoch: 5 batch: 10 current batch loss: 0.2252642959356308 current lr: 0.00059049\n",
            "epoch: 5 batch: 11 current batch loss: 0.20855242013931274 current lr: 0.00059049\n",
            "epoch: 5 batch: 12 current batch loss: 0.21876807510852814 current lr: 0.00059049\n",
            "epoch: 5 batch: 13 current batch loss: 0.22802197933197021 current lr: 0.00059049\n",
            "epoch: 5 batch: 14 current batch loss: 0.22142888605594635 current lr: 0.00059049\n",
            "epoch: 5 batch: 15 current batch loss: 0.22756248712539673 current lr: 0.00059049\n",
            "epoch: 5 batch: 16 current batch loss: 0.23205266892910004 current lr: 0.00059049\n",
            "epoch: 5 batch: 17 current batch loss: 0.20879314839839935 current lr: 0.00059049\n",
            "epoch: 5 batch: 18 current batch loss: 0.1855924427509308 current lr: 0.00059049\n",
            "epoch: 5 batch: 19 current batch loss: 0.21493279933929443 current lr: 0.00059049\n",
            "epoch: 5 batch: 20 current batch loss: 0.21744447946548462 current lr: 0.00059049\n",
            "epoch: 5 batch: 21 current batch loss: 0.21664731204509735 current lr: 0.00059049\n",
            "epoch: 5 batch: 22 current batch loss: 0.21636317670345306 current lr: 0.00059049\n",
            "epoch: 5 batch: 23 current batch loss: 0.2047373503446579 current lr: 0.00059049\n",
            "epoch: 5 batch: 24 current batch loss: 0.22680361568927765 current lr: 0.00059049\n",
            "epoch: 5 batch: 25 current batch loss: 0.2210637778043747 current lr: 0.00059049\n",
            "epoch: 5 batch: 26 current batch loss: 0.21827545762062073 current lr: 0.00059049\n",
            "epoch: 5 batch: 27 current batch loss: 0.21905960142612457 current lr: 0.00059049\n",
            "epoch: 5 batch: 28 current batch loss: 0.21486768126487732 current lr: 0.00059049\n",
            "epoch: 5 batch: 29 current batch loss: 0.23195596039295197 current lr: 0.00059049\n",
            "epoch: 6 batch: 0 current batch loss: 0.21621789038181305 current lr: 0.000531441\n",
            "epoch: 6 batch: 1 current batch loss: 0.2211659699678421 current lr: 0.000531441\n",
            "epoch: 6 batch: 2 current batch loss: 0.19052398204803467 current lr: 0.000531441\n",
            "epoch: 6 batch: 3 current batch loss: 0.18861791491508484 current lr: 0.000531441\n",
            "epoch: 6 batch: 4 current batch loss: 0.21282486617565155 current lr: 0.000531441\n",
            "epoch: 6 batch: 5 current batch loss: 0.19413334131240845 current lr: 0.000531441\n",
            "epoch: 6 batch: 6 current batch loss: 0.19700008630752563 current lr: 0.000531441\n",
            "epoch: 6 batch: 7 current batch loss: 0.1912497878074646 current lr: 0.000531441\n",
            "epoch: 6 batch: 8 current batch loss: 0.19916464388370514 current lr: 0.000531441\n",
            "epoch: 6 batch: 9 current batch loss: 0.18774543702602386 current lr: 0.000531441\n",
            "epoch: 6 batch: 10 current batch loss: 0.20157155394554138 current lr: 0.000531441\n",
            "epoch: 6 batch: 11 current batch loss: 0.18528728187084198 current lr: 0.000531441\n",
            "epoch: 6 batch: 12 current batch loss: 0.1799831986427307 current lr: 0.000531441\n",
            "epoch: 6 batch: 13 current batch loss: 0.20150671899318695 current lr: 0.000531441\n",
            "epoch: 6 batch: 14 current batch loss: 0.20596681535243988 current lr: 0.000531441\n",
            "epoch: 6 batch: 15 current batch loss: 0.18999478220939636 current lr: 0.000531441\n",
            "epoch: 6 batch: 16 current batch loss: 0.19312502443790436 current lr: 0.000531441\n",
            "epoch: 6 batch: 17 current batch loss: 0.19401800632476807 current lr: 0.000531441\n",
            "epoch: 6 batch: 18 current batch loss: 0.20918570458889008 current lr: 0.000531441\n",
            "epoch: 6 batch: 19 current batch loss: 0.19039389491081238 current lr: 0.000531441\n",
            "epoch: 6 batch: 20 current batch loss: 0.18524493277072906 current lr: 0.000531441\n",
            "epoch: 6 batch: 21 current batch loss: 0.21232090890407562 current lr: 0.000531441\n",
            "epoch: 6 batch: 22 current batch loss: 0.19140899181365967 current lr: 0.000531441\n",
            "epoch: 6 batch: 23 current batch loss: 0.20955495536327362 current lr: 0.000531441\n",
            "epoch: 6 batch: 24 current batch loss: 0.18268902599811554 current lr: 0.000531441\n",
            "epoch: 6 batch: 25 current batch loss: 0.2011994570493698 current lr: 0.000531441\n",
            "epoch: 6 batch: 26 current batch loss: 0.19149118661880493 current lr: 0.000531441\n",
            "epoch: 6 batch: 27 current batch loss: 0.19033879041671753 current lr: 0.000531441\n",
            "epoch: 6 batch: 28 current batch loss: 0.1773964762687683 current lr: 0.000531441\n",
            "epoch: 6 batch: 29 current batch loss: 0.18180227279663086 current lr: 0.000531441\n",
            "epoch: 7 batch: 0 current batch loss: 0.1715492308139801 current lr: 0.0004782969\n",
            "epoch: 7 batch: 1 current batch loss: 0.17400908470153809 current lr: 0.0004782969\n",
            "epoch: 7 batch: 2 current batch loss: 0.1590031385421753 current lr: 0.0004782969\n",
            "epoch: 7 batch: 3 current batch loss: 0.16426588594913483 current lr: 0.0004782969\n",
            "epoch: 7 batch: 4 current batch loss: 0.18510791659355164 current lr: 0.0004782969\n",
            "epoch: 7 batch: 5 current batch loss: 0.18771478533744812 current lr: 0.0004782969\n",
            "epoch: 7 batch: 6 current batch loss: 0.17787347733974457 current lr: 0.0004782969\n",
            "epoch: 7 batch: 7 current batch loss: 0.17172770202159882 current lr: 0.0004782969\n",
            "epoch: 7 batch: 8 current batch loss: 0.18192142248153687 current lr: 0.0004782969\n",
            "epoch: 7 batch: 9 current batch loss: 0.19558589160442352 current lr: 0.0004782969\n",
            "epoch: 7 batch: 10 current batch loss: 0.16911983489990234 current lr: 0.0004782969\n",
            "epoch: 7 batch: 11 current batch loss: 0.17559538781642914 current lr: 0.0004782969\n",
            "epoch: 7 batch: 12 current batch loss: 0.17386125028133392 current lr: 0.0004782969\n",
            "epoch: 7 batch: 13 current batch loss: 0.18934760987758636 current lr: 0.0004782969\n",
            "epoch: 7 batch: 14 current batch loss: 0.1671385020017624 current lr: 0.0004782969\n",
            "epoch: 7 batch: 15 current batch loss: 0.1827782243490219 current lr: 0.0004782969\n",
            "epoch: 7 batch: 16 current batch loss: 0.17832022905349731 current lr: 0.0004782969\n",
            "epoch: 7 batch: 17 current batch loss: 0.15999603271484375 current lr: 0.0004782969\n",
            "epoch: 7 batch: 18 current batch loss: 0.19212250411510468 current lr: 0.0004782969\n",
            "epoch: 7 batch: 19 current batch loss: 0.16355042159557343 current lr: 0.0004782969\n",
            "epoch: 7 batch: 20 current batch loss: 0.15146437287330627 current lr: 0.0004782969\n",
            "epoch: 7 batch: 21 current batch loss: 0.17171908915042877 current lr: 0.0004782969\n",
            "epoch: 7 batch: 22 current batch loss: 0.16928501427173615 current lr: 0.0004782969\n",
            "epoch: 7 batch: 23 current batch loss: 0.15900301933288574 current lr: 0.0004782969\n",
            "epoch: 7 batch: 24 current batch loss: 0.18284374475479126 current lr: 0.0004782969\n",
            "epoch: 7 batch: 25 current batch loss: 0.1764187216758728 current lr: 0.0004782969\n",
            "epoch: 7 batch: 26 current batch loss: 0.16923318803310394 current lr: 0.0004782969\n",
            "epoch: 7 batch: 27 current batch loss: 0.14621604979038239 current lr: 0.0004782969\n",
            "epoch: 7 batch: 28 current batch loss: 0.13643768429756165 current lr: 0.0004782969\n",
            "epoch: 7 batch: 29 current batch loss: 0.15178784728050232 current lr: 0.0004782969\n"
          ]
        }
      ],
      "source": [
        "net_with_scheduler = MLP()\n",
        "optimizer = torch.optim.Adam(net_with_scheduler.parameters(), 0.001)   #initial learning rate of 0.001. \n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)    #updates the learning rate after each epoch. There are many ways to do that: StepLR multiplies learning rate by gamma\n",
        "\n",
        "net_with_scheduler.train()    #it notifies the network layers (especially batchnorm or dropout layers, which we don't use in this example) that we are doing traning\n",
        "for epoch in range(8):  #  an epoch is a training run through the whole data set\n",
        "\n",
        "    loss = 0.0\n",
        "    for batch, data in enumerate(trainloader):\n",
        "        batch_inputs, batch_labels = data\n",
        "        #batch_inputs.squeeze(1)     #alternatively if not for a Flatten layer, squeeze() could be used to remove the second order of the tensor, the Channel, which is one-dimensional (this index can be equal to 0 only)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_outputs = net_with_scheduler(batch_inputs)   #this line calls the forward(self, x) method of the MLP object. Please note, that the last layer of the MLP is linear \n",
        "                                            #and MLP doesn't apply \n",
        "                                            #the nonlinear activation after the last layer\n",
        "        loss = torch.nn.functional.cross_entropy(batch_outputs, batch_labels, reduction = \"mean\") #instead, nonlinear softmax is applied internally in THIS loss function\n",
        "        \n",
        "        print(\"epoch:\", epoch, \"batch:\", batch, \"current batch loss:\", loss.item(), \"current lr:\", scheduler.get_last_lr()[0]) \n",
        "        loss.backward()       #this computes gradients as we have seen in previous workshops\n",
        "        optimizer.step()     #but this line in fact updates our neural network. \n",
        "                                \n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aa1db9e-263a-421e-a23f-1b6918fd4592",
      "metadata": {
        "id": "6aa1db9e-263a-421e-a23f-1b6918fd4592"
      },
      "source": [
        "![pencil](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/pencil2.png) \n",
        "### Your task #6\n",
        "\n",
        "Well, it seems that we were able to get the learning rate to levels of 0.1 even without a scheduler. Can you bring it under 0.05? Can you keep it under 0.05? Maybe the proposed gamma was to low (0.9 only)?. Please experiment with different settings for the optimizer learning rate and different scheduler settings. There are other schedulers you can experiment with, too. Please verify what would happen if the nets were allowed to train for more training epochs.\n",
        "\n",
        "![ledger](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/ledger.png) Some other schedulers you might want to experiment with: \n",
        "- Exponential LR - decays the learning rate of each parameter group by gamma every epoch - [link to documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ExponentialLR.html) \n",
        "- Step LR - more general then the Exponential LR: decays the learning rate of each parameter group by gamma every step_size epochs - [link to documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html)\n",
        "- Cosine Annealing LR - learning rate follows the first quarter of the cosine curve - [link to documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html)\n",
        "- Cosine with Warm Restarts - learning rate follows the first quarter of the cosine curve and restarts after a predefined number of epochs - [link to documentation](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html)\n",
        "\n",
        "![pencil](https://www.webfx.com/wp-content/themes/fx/assets/img/tools/emoji-cheat-sheet/graphics/emojis/pencil2.png) \n",
        "### Your task #7\n",
        "\n",
        "Please explain, what are the dangers of bringing the loss too low? What is an *overtrained* neural network? How can one prevent it?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad5ae403-3ea0-4c28-896b-2cb5ec67492f",
      "metadata": {
        "id": "ad5ae403-3ea0-4c28-896b-2cb5ec67492f"
      },
      "source": [
        "### Testing\n",
        "\n",
        "Now we will test those two nets - the one without and the one with the scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8ba700ae-97ca-41fa-8105-89980c5c9406",
      "metadata": {
        "id": "8ba700ae-97ca-41fa-8105-89980c5c9406",
        "outputId": "102dd482-9208-4116-87c7-f33f538e5c35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  0.9683\n"
          ]
        }
      ],
      "source": [
        "good = 0\n",
        "wrong = 0\n",
        "\n",
        "net.eval()              #it notifies the network layers (especially batchnorm or dropout layers, which we don't use in this example) that we are doing evaluation\n",
        "with torch.no_grad():   #it prevents that the net learns during evalution. The gradients are not computed, so this makes it faster, too\n",
        "    for batch, data in enumerate(testloader): #batches in test are of size 1\n",
        "        datapoint, label = data\n",
        "\n",
        "        prediction = net(datapoint)                  #prediction has values representing the \"prevalence\" of the corresponding class\n",
        "        classification = torch.argmax(prediction)    #the class is the index of maximal \"prevalence\"\n",
        "\n",
        "        if classification.item() == label.item():\n",
        "            good += 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "        \n",
        "print(\"accuracy = \", good/(good+wrong))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2d35d8ad-e858-40d5-8702-20db94f56879",
      "metadata": {
        "id": "2d35d8ad-e858-40d5-8702-20db94f56879",
        "outputId": "679eb551-9d9a-4fc5-d1e6-20a8a4d5d647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy =  0.9589\n"
          ]
        }
      ],
      "source": [
        "good = 0\n",
        "wrong = 0\n",
        "\n",
        "net_with_scheduler.eval()   #it notifies the network layers (especially batchnorm or dropout layers, which we don't use in this example) that we are doing evaluation\n",
        "with torch.no_grad():       #it prevents that the net learns during evalution. The gradients are not computed, so this makes it faster, too\n",
        "    for batch, data in enumerate(testloader): #batches in test are of size 1\n",
        "\n",
        "        datapoint, label = data\n",
        "\n",
        "        prediction = net_with_scheduler(datapoint)                  #prediction has values representing the \"prevalence\" of the corresponding class\n",
        "        classification = torch.argmax(prediction)                   #the class is the index of maximal \"prevalence\"\n",
        "\n",
        "        if classification.item() == label.item():\n",
        "            good += 1\n",
        "        else:\n",
        "            wrong += 1\n",
        "        \n",
        "print(\"accuracy = \", good/(good+wrong))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4831d2c-ee3f-42be-969b-627d888692c8",
      "metadata": {
        "id": "e4831d2c-ee3f-42be-969b-627d888692c8"
      },
      "source": [
        "Well, not bad. Now it is your turn to experiment - change the number and sizes of layers in out neural networks, change the activation function, play with the learning rate and the optimizer and the scheduler."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e7ce9bd32d640a0b42f1ff8392393cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d720433201645e58e49476dfc89df4f",
              "IPY_MODEL_1fa86ad8cc524480a75bd21fbd8015f3",
              "IPY_MODEL_eb8f58eae2c8485896ba7eeeb516c540"
            ],
            "layout": "IPY_MODEL_a8e292933de94bb5a0b1743caea484e9"
          }
        },
        "9d720433201645e58e49476dfc89df4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f9f3f87db7345a4bc75fc3ff209e546",
            "placeholder": "​",
            "style": "IPY_MODEL_80eb6ec39ddd48e6b8171f71b327314f",
            "value": "100%"
          }
        },
        "1fa86ad8cc524480a75bd21fbd8015f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158d6a1af0ce47bf82776473306641a9",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c845ff5b498426eba1fcfd45d38509c",
            "value": 9912422
          }
        },
        "eb8f58eae2c8485896ba7eeeb516c540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a5ea9e3844423590266267c0877618",
            "placeholder": "​",
            "style": "IPY_MODEL_2b47e8cd73e04131abc85eaf9c37bb3e",
            "value": " 9912422/9912422 [00:00&lt;00:00, 16075980.32it/s]"
          }
        },
        "a8e292933de94bb5a0b1743caea484e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9f3f87db7345a4bc75fc3ff209e546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80eb6ec39ddd48e6b8171f71b327314f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "158d6a1af0ce47bf82776473306641a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c845ff5b498426eba1fcfd45d38509c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3a5ea9e3844423590266267c0877618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b47e8cd73e04131abc85eaf9c37bb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "240502466e4e4c238309f3f5d61a9449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1d1046806e74950aa807c06266c9548",
              "IPY_MODEL_4619180ec58541099ce9bcca1af795ab",
              "IPY_MODEL_ae2022cbe08f447489e154f4cf0924ff"
            ],
            "layout": "IPY_MODEL_30a8a17ed1cc453ea2234529ed918f29"
          }
        },
        "b1d1046806e74950aa807c06266c9548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd1185e0867499299d1e059570ed74c",
            "placeholder": "​",
            "style": "IPY_MODEL_1a149ad697784f3ab41ddccdbdf3e4b5",
            "value": "100%"
          }
        },
        "4619180ec58541099ce9bcca1af795ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3b33aca55842b9a8fcd9507594448a",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe9872aceb1248c79ca2c60ae2152eb6",
            "value": 28881
          }
        },
        "ae2022cbe08f447489e154f4cf0924ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba79ce8ca9f4d62be8d2b883838f526",
            "placeholder": "​",
            "style": "IPY_MODEL_1a35683699be427cb7e6d85a61e76369",
            "value": " 28881/28881 [00:00&lt;00:00, 463207.44it/s]"
          }
        },
        "30a8a17ed1cc453ea2234529ed918f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd1185e0867499299d1e059570ed74c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a149ad697784f3ab41ddccdbdf3e4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b3b33aca55842b9a8fcd9507594448a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9872aceb1248c79ca2c60ae2152eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ba79ce8ca9f4d62be8d2b883838f526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a35683699be427cb7e6d85a61e76369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe7832b129c54e8facfc96b36d490bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4e958896a134b0bbac8bcf9922bdad3",
              "IPY_MODEL_579b7b34cb714c8ea7a4ca51b1dd7f45",
              "IPY_MODEL_fa3e8d88776a4ca6865cd28e3d4a56ca"
            ],
            "layout": "IPY_MODEL_88d9fb6c8d9b41c09d85aae5462f0faa"
          }
        },
        "f4e958896a134b0bbac8bcf9922bdad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90a257c64053484b9a1142d95714b8ec",
            "placeholder": "​",
            "style": "IPY_MODEL_b468736363b24e8394b817238f924f3f",
            "value": "100%"
          }
        },
        "579b7b34cb714c8ea7a4ca51b1dd7f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e7bd542642e44dcb2ac53f6fbe9ee98",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecbe7f1143004f279167da08478ae8ff",
            "value": 1648877
          }
        },
        "fa3e8d88776a4ca6865cd28e3d4a56ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d67d908fc0423298b9a4c08f73a5cc",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d0fa5a59464cd290977e94c39a0e67",
            "value": " 1648877/1648877 [00:00&lt;00:00, 5120033.94it/s]"
          }
        },
        "88d9fb6c8d9b41c09d85aae5462f0faa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90a257c64053484b9a1142d95714b8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b468736363b24e8394b817238f924f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e7bd542642e44dcb2ac53f6fbe9ee98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecbe7f1143004f279167da08478ae8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4d67d908fc0423298b9a4c08f73a5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d0fa5a59464cd290977e94c39a0e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49ddedd508f34300b9d5e80a99a37849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c820aec5068d420ca41baf7ab5e97141",
              "IPY_MODEL_784194ed3c014b87b75598bb79ea4e33",
              "IPY_MODEL_34d510c44f444b71a867849d8db00780"
            ],
            "layout": "IPY_MODEL_2de41eab99484a239812c70f8c0120f3"
          }
        },
        "c820aec5068d420ca41baf7ab5e97141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7058d0dcccf144688e05b4cd4157a2db",
            "placeholder": "​",
            "style": "IPY_MODEL_ae2fe29e3d3f4f5a9d7e834b3b323624",
            "value": "100%"
          }
        },
        "784194ed3c014b87b75598bb79ea4e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e03dff88b819422c9361b8729b810bff",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_869a339cc1684ff6a8f32f7b253b6096",
            "value": 4542
          }
        },
        "34d510c44f444b71a867849d8db00780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f57aecfa5174e958309bb4946b6046e",
            "placeholder": "​",
            "style": "IPY_MODEL_b6e9e6eb07764ccd8c39e2a538207339",
            "value": " 4542/4542 [00:00&lt;00:00, 41118.05it/s]"
          }
        },
        "2de41eab99484a239812c70f8c0120f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7058d0dcccf144688e05b4cd4157a2db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2fe29e3d3f4f5a9d7e834b3b323624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e03dff88b819422c9361b8729b810bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869a339cc1684ff6a8f32f7b253b6096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f57aecfa5174e958309bb4946b6046e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e9e6eb07764ccd8c39e2a538207339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}