{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "M33M9YukJ3BS",
        "fXMSis0CLdLQ",
        "2IGml3MILBvd",
        "qpCCWPQdMWmH",
        "X3AmiDL_xKY1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Rudiments of Natural Language Processing: Attention"
      ],
      "metadata": {
        "id": "U_5B9itxJeRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the third part of the NLP workshop at the Center for Machine Learning. In this notebook we extend the previously created model with an attention mechanism. We do the following:\n",
        "\n",
        "*   Gather some prerequisites\n",
        "*   Restore previous datapipes, vocabulary, and model\n",
        "*   Implement the attention mechanism\n",
        "*   Implement multi-head attention\n",
        "*   Train and evaluate models with attention\n",
        "*   Inspect the attention weights\n",
        "\n"
      ],
      "metadata": {
        "id": "Je9MILQKmT5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites"
      ],
      "metadata": {
        "id": "M33M9YukJ3BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you even start go to the menu above and make sure that your execution environment uses the GPU. Otherwise the model will train very slowly. If you change the environment later you will need to rerun the notebook from the begining. Now install the missing dependencies:"
      ],
      "metadata": {
        "id": "18gvezsIJ0ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker"
      ],
      "metadata": {
        "id": "hFRX-ae5J9TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary modules:"
      ],
      "metadata": {
        "id": "IMX7ZmvrKIzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.colab as colab\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch\n",
        "import torchdata\n",
        "import torchtext"
      ],
      "metadata": {
        "id": "y59dcjmQKiP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first notebook we saved some data in your home directory on the google drive. To read these data mount your drive:"
      ],
      "metadata": {
        "id": "INP6lGGOKY8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colab.drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V8Izfe2DKo3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your home directory is now mounted as `drive/MyDrive`. Check it by listing its contents:"
      ],
      "metadata": {
        "id": "3WdFBOqxKuWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/"
      ],
      "metadata": {
        "id": "i8L0659PKygE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should see the files `vocab.pkl`, `train_data.csv` and `valid_data.csv`. If not run the first notebook to produce them."
      ],
      "metadata": {
        "id": "a1X2slPrK5Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datapipes, vocabulary, and model"
      ],
      "metadata": {
        "id": "fXMSis0CLdLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook we created datapipes that read the training and validation data. Create them again:"
      ],
      "metadata": {
        "id": "sqc4sqkcnCod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(sample):\n",
        "    label0, *index1 = sample\n",
        "    label0 = float(label0)\n",
        "    index1 = torch.tensor([int(index0) for index0 in index1])\n",
        "    return label0, index1\n",
        "\n",
        "def collate(batch):\n",
        "    label1, index2 = zip(*batch)\n",
        "    label1 = torch.tensor(label1)\n",
        "    index2 = torch.nn.utils.rnn.pad_sequence(index2, padding_value = 0, batch_first = True)\n",
        "    return label1, index2\n",
        "\n",
        "train_pipe = torchdata.datapipes.iter.FileOpener(['drive/MyDrive/train_data.csv'])\n",
        "train_pipe = train_pipe.parse_csv()\n",
        "train_pipe = train_pipe.map(decode)\n",
        "train_pipe = train_pipe.shuffle(buffer_size = 16384)\n",
        "train_pipe = train_pipe.batch(64)\n",
        "train_pipe = train_pipe.collate(collate)\n",
        "\n",
        "valid_pipe = torchdata.datapipes.iter.FileOpener(['drive/MyDrive/valid_data.csv'])\n",
        "valid_pipe = valid_pipe.parse_csv()\n",
        "valid_pipe = valid_pipe.map(decode)\n",
        "valid_pipe = valid_pipe.batch(64)\n",
        "valid_pipe = valid_pipe.collate(collate)"
      ],
      "metadata": {
        "id": "H_ED069ALyga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also created a vocabulary and saved it to your google drive. Load it:"
      ],
      "metadata": {
        "id": "SoIkuLqynWHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/vocab.pkl', 'rb') as stream:\n",
        "    vocab = pickle.load(stream)"
      ],
      "metadata": {
        "id": "SKvK_3bbMWQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the vocabulary size and set it as the number of unique words or word indices:"
      ],
      "metadata": {
        "id": "7Xl_WNE9r635"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices = len(vocab)"
      ],
      "metadata": {
        "id": "DXF4lUVssBi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the number of embedding features to the previous value of four:"
      ],
      "metadata": {
        "id": "6VoiJhw4qviZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = 4"
      ],
      "metadata": {
        "id": "40tF0GyAN3kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook we implemented the following model:"
      ],
      "metadata": {
        "id": "7bm4H-4ULNCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):            #(samples, frames)\n",
        "        feature = self.encoder(index)    #(samples, frames, features)\n",
        "        feature = feature.mean(1)        #(samples, features)\n",
        "        logit = self.classifier(feature) #(samples, 1)\n",
        "        logit = logit.flatten()          #(samples)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "tTYeTTKeLFUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate it:"
      ],
      "metadata": {
        "id": "FLjhqUDzrTlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "h4dvrwE4rkwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just as a reminder print the input and output shapes for a few batches:"
      ],
      "metadata": {
        "id": "7yff4QkkrpvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for truth_label, index in train_pipe.header(10):\n",
        "    print(index.size())\n",
        "    logit = model(index)\n",
        "    print(logit.size())\n",
        "    print()"
      ],
      "metadata": {
        "id": "04BLmIRKM76O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "2IGml3MILBvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our simple model averages the embedding features of all the words in a review. We will now replace the arithmetic mean with a weighted average. The weights will be learned during training to pay more attention to important words. Look at the previous simple model:"
      ],
      "metadata": {
        "id": "Rgm_veoKsu4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):            #(samples, frames)\n",
        "        feature = self.encoder(index)    #(samples, frames, features)\n",
        "        feature = feature.mean(1)        #(samples, features)\n",
        "        logit = self.classifier(feature) #(samples, 1)\n",
        "        logit = logit.flatten()          #(samples)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "Qp09YRIavSOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Averaging the features along the `frames` axis removes this dimension by default. Now force the mean operation to keep it:"
      ],
      "metadata": {
        "id": "a5dqzkagvcCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):            #(samples, frames)\n",
        "        feature = self.encoder(index)    #(samples, frames, features)\n",
        "        feature = feature.mean(1, True)  #(samples, 1, features)\n",
        "        logit = self.classifier(feature) #(samples, 1, 1)\n",
        "        logit = logit.flatten()          #(samples)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "nVtiZRW5OEfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `frames` dimension is now shrinked to the size of one. The classifier layer works only on the `features` axis and also reduces its size to one. The singleton dimensions created in this way are then removed by the flatten operation. Now read the dimensions of the incoming batch and replace the arithmetic average with a weighted mean with equal weights. Implement the weighting as matrix multiplication:"
      ],
      "metadata": {
        "id": "8XaUxTY7vrsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):                                 #(samples, frames)\n",
        "        feature = self.encoder(index)                         #(samples, frames, features)\n",
        "        samples, frames, features = feature.size()\n",
        "        weight = torch.full((samples, 1, frames), 1 / frames) #(samples, 1, frames)\n",
        "        feature = weight @ feature                            #(samples, 1, features)\n",
        "        logit = self.classifier(feature)                      #(samples, 1, 1)\n",
        "        logit = logit.flatten()                               #(samples)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "MgLzfaCFOPUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the weights have a `samples` dimension and will soon be different for each sample in the batch. The matrix multiplication works separately for each sample and actually multiplies two-dimensional matrices. Equal weights still yield the artihmetic mean but formally our model already calculates a weighted average. Move this average to a separate attention module:"
      ],
      "metadata": {
        "id": "IFk81OBdz_YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "    def forward(self, feature):                               #(samples, frames, features)\n",
        "        samples, frames, features = feature.size()\n",
        "        weight = torch.full((samples, 1, frames), 1 / frames) #(samples, 1, frames)\n",
        "        feature = weight @ feature                            #(samples, 1, features)\n",
        "        return feature\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):             #(samples, frames)\n",
        "        feature = self.encoder(index)     #(samples, frames, features)\n",
        "        feature = self.attention(feature) #(samples, 1, features)\n",
        "        logit = self.classifier(feature)  #(samples, 1, 1)\n",
        "        logit = logit.flatten()           #(samples)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "J6XCkYNhOl9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From now on we will work only on the attention module:"
      ],
      "metadata": {
        "id": "bE4h3Ekd2H4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "    def forward(self, feature):                               #(samples, frames, features)\n",
        "        samples, frames, features = feature.size()\n",
        "        weight = torch.full((samples, 1, frames), 1 / frames) #(samples, 1, frames)\n",
        "        feature = weight @ feature                            #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "8405xAZc4PP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that weights must be positive and sum up to one along the `frames` axis. So they can be produced by the softmax function applied along this axis. In the context of attention the softmax inputs are called energies and have the same shape as the weights. Use zero energies for now:"
      ],
      "metadata": {
        "id": "AcNSmnGY4PuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "    def forward(self, feature):                         #(samples, frames, features)\n",
        "        samples, frames, features = feature.size()\n",
        "        energy = torch.zeros((samples, 1, frames))      #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2) #(samples, 1, frames)\n",
        "        feature = weight @ feature                      #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "Ocol6lPqPJyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With zero energies the softmax yields equal weights so the model still calculates the arithmetic mean. This will change now. Now the energies will be scalar products of the embedding features with a single vector called query. It is convenient to give the query vector two singleton dimensions and calculate the scalar products as matrix multiplication:"
      ],
      "metadata": {
        "id": "MUOIZh9X4xmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.empty(1, 1, features)\n",
        "    def forward(self, feature):                         #(samples, frames, features)\n",
        "        energy = self.query @ feature.transpose(1, 2)   #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2) #(samples, 1, frames)\n",
        "        feature = weight @ feature                      #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "WTldM0t06nD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new matrix multiplication broadcasts the first dimension of the query vector as if there was a separate but equal query vector for each sample in the batch. Then for each sample scalar products of the query vector with all the feature vectors in this sample are calculated. These scalar products are larger or smaller for frames with features similar or different from the query vector respectively. Such scalar products become the energies which are fed to the softmax function and converted to weights. Now the weighted average indeed pays more attention to frames that are in a sense similar to the query vector. Till now the query vector had some undefined values but we will now properly initialize it and make it a trainable parameter of the model:"
      ],
      "metadata": {
        "id": "8GRLW0H463bH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "    def forward(self, feature):                         #(samples, frames, features)\n",
        "        energy = self.query @ feature.transpose(1, 2)   #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2) #(samples, 1, frames)\n",
        "        feature = weight @ feature                      #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "DIC_Lr18Pryw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the query vector will be learned from data during training together with all the remaining parameters of the model. This is the basic version of the attention module that could already be used. But we will stll enrich it a bit. Note that the input features are first used to calculate the energies and then to calculate the output features by weighting. We usually say that they are first used as keys and then as values. To make it more explicit introduce key and value vectors just equal to the input features:"
      ],
      "metadata": {
        "id": "aG-3gTJMA-5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "    def forward(self, feature):                         #(samples, frames, features)\n",
        "        key = feature                                   #(samples, frames, features)\n",
        "        value = feature                                 #(samples, frames, features)\n",
        "        energy = self.query @ key.transpose(1, 2)       #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2) #(samples, 1, frames)\n",
        "        feature = weight @ value                        #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "brn0k1gBQFcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now say that the key and value vectors need not be exactly equal to the input features but may be multiplied by some square matrices. These matrices will also be trainable parameters of the model:"
      ],
      "metadata": {
        "id": "g1tAMcw0D5y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "    def forward(self, feature):                         #(samples, frames, features)\n",
        "        key = feature @ self.weightK                    #(samples, frames, features)\n",
        "        value = feature @ self.weightV                  #(samples, frames, features)\n",
        "        energy = self.query @ key.transpose(1, 2)       #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2) #(samples, 1, frames)\n",
        "        feature = weight @ value                        #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "BPyb9aa4QRA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is called a query-key-value form of the attention mechanism. Let us now use it in our model instead of the initial arithmetic mean:"
      ],
      "metadata": {
        "id": "tn6RZ1ynE3Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):             #(samples, frames)\n",
        "        feature = self.encoder(index)     #(samples, frames, features)\n",
        "        feature = self.attention(feature) #(samples, 1, features)\n",
        "        logit = self.classifier(feature)  #(samples, 1, 1)\n",
        "        logit = logit.flatten()           #(samples)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "t4FIeL4WQfgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that apart from the new attention the model has not changed. Instantiate it:"
      ],
      "metadata": {
        "id": "TI2AFxxjFUDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().cuda()"
      ],
      "metadata": {
        "id": "rb2lE1rJfsa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train it:"
      ],
      "metadata": {
        "id": "kVAZohDSFhTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = list()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "max_valid_accuracy = torch.tensor(0.).cuda()\n",
        "for epoch in range(128):\n",
        "    valid_accuracy = torch.tensor(0).cuda()\n",
        "    samples = torch.tensor(0).cuda()\n",
        "    for truth_label, index in valid_pipe:\n",
        "        truth_label, index = truth_label.cuda(), index.cuda()\n",
        "        logit = model(index)\n",
        "        model_label = logit.gt(0).float()\n",
        "        hit = model_label.eq(truth_label)\n",
        "        valid_accuracy += hit.count_nonzero()\n",
        "        samples += hit.numel()\n",
        "    valid_accuracy = valid_accuracy / samples\n",
        "    if max_valid_accuracy.lt(valid_accuracy):\n",
        "        max_valid_accuracy = valid_accuracy\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    train_accuracy = torch.tensor(0).cuda()\n",
        "    samples = torch.tensor(0).cuda()\n",
        "    for truth_label, index in train_pipe:\n",
        "        truth_label, index = truth_label.cuda(), index.cuda()\n",
        "        logit = model(index)\n",
        "        model_label = logit.gt(0).float()\n",
        "        hit = model_label.eq(truth_label)\n",
        "        train_accuracy += hit.count_nonzero()\n",
        "        samples += hit.numel()\n",
        "        loss = torch.nn.functional.binary_cross_entropy_with_logits(logit, truth_label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_accuracy = train_accuracy / samples\n",
        "    history.append((epoch, train_accuracy.item(), valid_accuracy.item()))\n",
        "    print('%5i %5.3f %5.3f' % (epoch, train_accuracy, valid_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tM8illMBR0sZ",
        "outputId": "61d76f51-4885-4744-b523-d927862395dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0 0.506 0.500\n",
            "    1 0.657 0.538\n",
            "    2 0.796 0.749\n",
            "    3 0.837 0.813\n",
            "    4 0.856 0.838\n",
            "    5 0.871 0.850\n",
            "    6 0.883 0.861\n",
            "    7 0.891 0.871\n",
            "    8 0.898 0.876\n",
            "    9 0.905 0.880\n",
            "   10 0.911 0.882\n",
            "   11 0.917 0.882\n",
            "   12 0.923 0.885\n",
            "   13 0.926 0.886\n",
            "   14 0.929 0.886\n",
            "   15 0.933 0.887\n",
            "   16 0.938 0.886\n",
            "   17 0.942 0.885\n",
            "   18 0.946 0.886\n",
            "   19 0.949 0.882\n",
            "   20 0.952 0.884\n",
            "   21 0.956 0.885\n",
            "   22 0.957 0.881\n",
            "   23 0.961 0.881\n",
            "   24 0.964 0.881\n",
            "   25 0.966 0.880\n",
            "   26 0.969 0.880\n",
            "   27 0.971 0.880\n",
            "   28 0.974 0.879\n",
            "   29 0.976 0.878\n",
            "   30 0.978 0.875\n",
            "   31 0.981 0.874\n",
            "   32 0.982 0.874\n",
            "   33 0.984 0.870\n",
            "   34 0.985 0.872\n",
            "   35 0.987 0.869\n",
            "   36 0.988 0.868\n",
            "   37 0.990 0.864\n",
            "   38 0.991 0.865\n",
            "   39 0.992 0.860\n",
            "   40 0.993 0.859\n",
            "   41 0.994 0.860\n",
            "   42 0.995 0.858\n",
            "   43 0.996 0.856\n",
            "   44 0.997 0.856\n",
            "   45 0.997 0.854\n",
            "   46 0.998 0.850\n",
            "   47 0.998 0.852\n",
            "   48 0.999 0.851\n",
            "   49 0.999 0.849\n",
            "   50 0.999 0.847\n",
            "   51 0.999 0.847\n",
            "   52 1.000 0.845\n",
            "   53 1.000 0.845\n",
            "   54 1.000 0.840\n",
            "   55 1.000 0.843\n",
            "   56 1.000 0.842\n",
            "   57 1.000 0.841\n",
            "   58 1.000 0.841\n",
            "   59 1.000 0.840\n",
            "   60 1.000 0.839\n",
            "   61 1.000 0.839\n",
            "   62 1.000 0.837\n",
            "   63 1.000 0.837\n",
            "   64 1.000 0.837\n",
            "   65 1.000 0.836\n",
            "   66 1.000 0.836\n",
            "   67 1.000 0.835\n",
            "   68 1.000 0.835\n",
            "   69 1.000 0.834\n",
            "   70 1.000 0.834\n",
            "   71 1.000 0.834\n",
            "   72 1.000 0.833\n",
            "   73 1.000 0.833\n",
            "   74 1.000 0.833\n",
            "   75 1.000 0.833\n",
            "   76 1.000 0.832\n",
            "   77 1.000 0.832\n",
            "   78 1.000 0.832\n",
            "   79 1.000 0.832\n",
            "   80 1.000 0.831\n",
            "   81 1.000 0.831\n",
            "   82 1.000 0.832\n",
            "   83 1.000 0.831\n",
            "   84 1.000 0.831\n",
            "   85 1.000 0.831\n",
            "   86 1.000 0.831\n",
            "   87 1.000 0.830\n",
            "   88 1.000 0.830\n",
            "   89 1.000 0.830\n",
            "   90 1.000 0.830\n",
            "   91 1.000 0.829\n",
            "   92 1.000 0.830\n",
            "   93 1.000 0.830\n",
            "   94 1.000 0.830\n",
            "   95 1.000 0.829\n",
            "   96 1.000 0.829\n",
            "   97 1.000 0.829\n",
            "   98 1.000 0.828\n",
            "   99 1.000 0.830\n",
            "  100 1.000 0.829\n",
            "  101 1.000 0.828\n",
            "  102 1.000 0.828\n",
            "  103 1.000 0.832\n",
            "  104 1.000 0.832\n",
            "  105 1.000 0.831\n",
            "  106 1.000 0.832\n",
            "  107 1.000 0.831\n",
            "  108 1.000 0.831\n",
            "  109 1.000 0.832\n",
            "  110 1.000 0.832\n",
            "  111 1.000 0.831\n",
            "  112 1.000 0.831\n",
            "  113 1.000 0.831\n",
            "  114 1.000 0.831\n",
            "  115 1.000 0.831\n",
            "  116 1.000 0.831\n",
            "  117 1.000 0.831\n",
            "  118 1.000 0.831\n",
            "  119 1.000 0.831\n",
            "  120 1.000 0.831\n",
            "  121 1.000 0.831\n",
            "  122 1.000 0.831\n",
            "  123 1.000 0.831\n",
            "  124 1.000 0.831\n",
            "  125 1.000 0.831\n",
            "  126 1.000 0.831\n",
            "  127 1.000 0.831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the training and validation accuracies:"
      ],
      "metadata": {
        "id": "s0ztHeQOjvCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch, train_accuracy, valid_accuracy = zip(*history)\n",
        "\n",
        "plt.grid()\n",
        "plt.plot(epoch, train_accuracy)\n",
        "plt.plot(epoch, valid_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "-ahZnb-3jzME",
        "outputId": "c4ef035e-f5ac-4cfd-9073-4e4f8eaa58ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6a7b90b130>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare these results against the simple model with arithmetic mean. The training accuracy achieves 100% much faster now which means that the attention model can better reproduce the data. But the validation accuracy is lower than previously. This is because more complex models exhibit more overfitting. To improve the validation accuracy more training data would be required."
      ],
      "metadata": {
        "id": "YONLhLW-IrpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention weights"
      ],
      "metadata": {
        "id": "qpCCWPQdMWmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now inspect the attention weights learned during training. Modify the attention module so that it returns not only the output features but also the weights:"
      ],
      "metadata": {
        "id": "YzBtS2HdOWnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "    def forward(self, feature):                         #(samples, frames, features)\n",
        "        key = feature @ self.weightK                    #(samples, frames, features)\n",
        "        value = feature @ self.weightV                  #(samples, frames, features)\n",
        "        energy = self.query @ key.transpose(1, 2)       #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2) #(samples, 1, frames)\n",
        "        feature = weight @ value                        #(samples, 1, features)\n",
        "        return feature, weight"
      ],
      "metadata": {
        "id": "n57OenCekZMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also modify the model so that it reads the weights from the attention module and returns them as well:"
      ],
      "metadata": {
        "id": "dbZ48l0AOwL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):                     #(samples, frames)\n",
        "        feature = self.encoder(index)             #(samples, frames, features)\n",
        "        feature, weight = self.attention(feature) #(samples, 1, features)\n",
        "        logit = self.classifier(feature)          #(samples, 1, 1)\n",
        "        logit = logit.flatten()                   #(samples)\n",
        "        return logit, weight"
      ],
      "metadata": {
        "id": "FE2RTBNOOxJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate the model and read its parameters from disk:"
      ],
      "metadata": {
        "id": "0wPsVlTNPY9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "metadata": {
        "id": "_N_niGlrPn-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this way we load the parameters from the epoch when the model performed best on the validation data. Get the list of unique words in the vocabulary:"
      ],
      "metadata": {
        "id": "6EoGbQlMPvA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "itos = vocab.get_itos()"
      ],
      "metadata": {
        "id": "9tPt20XUSl0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate through some batches of the validation data. From each batch take the first sample and display the words together with their weights assigned by the attention mechanism:"
      ],
      "metadata": {
        "id": "nk9-WExtSuXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for truth_label1, index2 in valid_pipe.header(10):\n",
        "    colab.output.clear()\n",
        "    logit1, weight3 = model(index2)\n",
        "    for index0, weight0 in zip(index2[0], weight3[0, 0]):\n",
        "        print('%18s %5.3f' % (itos[index0], weight0))\n",
        "    input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6ISI5hIzj_4T",
        "outputId": "ec8b10ca-31e6-41dc-e571-2778dd8c63f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                as 0.001\n",
            "               you 0.002\n",
            "               may 0.004\n",
            "              know 0.003\n",
            "               the 0.000\n",
            "           subject 0.002\n",
            "              here 0.001\n",
            "               was 0.000\n",
            "                to 0.000\n",
            "               ask 0.004\n",
            "            eleven 0.004\n",
            "         directors 0.001\n",
            "              from 0.001\n",
            "               all 0.003\n",
            "              over 0.000\n",
            "               the 0.000\n",
            "             world 0.004\n",
            "                to 0.000\n",
            "              make 0.003\n",
            "              each 0.000\n",
            "                 a 0.000\n",
            "             short 0.001\n",
            "             movie 0.001\n",
            "                of 0.000\n",
            "           minutes 0.010\n",
            "           seconds 0.000\n",
            "               and 0.000\n",
            "               one 0.000\n",
            "             frame 0.002\n",
            "                we 0.000\n",
            "              have 0.001\n",
            "              here 0.001\n",
            "             <unk> 0.002\n",
            "             <unk> 0.002\n",
            "              iran 0.003\n",
            "              what 0.000\n",
            "            afghan 0.001\n",
            "           refugee 0.003\n",
            "              kids 0.000\n",
            "               can 0.003\n",
            "        understand 0.002\n",
            "                to 0.000\n",
            "               the 0.000\n",
            "            towers 0.001\n",
            "        collapsing 0.001\n",
            "              well 0.008\n",
            "           nothing 0.008\n",
            "                 a 0.000\n",
            "             great 0.008\n",
            "            lesson 0.002\n",
            "            claude 0.002\n",
            "           lelouch 0.000\n",
            "            france 0.008\n",
            "                 a 0.000\n",
            "              weak 0.013\n",
            "              plot 0.003\n",
            "              with 0.000\n",
            "                 a 0.000\n",
            "             great 0.008\n",
            "    cinematography 0.001\n",
            "              just 0.003\n",
            "           imagine 0.002\n",
            "                 a 0.000\n",
            "              deaf 0.003\n",
            "             woman 0.001\n",
            "            living 0.001\n",
            "                by 0.000\n",
            "               the 0.000\n",
            "               wtc 0.017\n",
            "               who 0.002\n",
            "              sees 0.004\n",
            "           without 0.002\n",
            "     understanding 0.005\n",
            "                it 0.002\n",
            "              that 0.000\n",
            "               her 0.001\n",
            "               dog 0.005\n",
            "             barks 0.001\n",
            "              well 0.008\n",
            "              just 0.003\n",
            "               see 0.005\n",
            "                it 0.002\n",
            "           youssef 0.003\n",
            "           chahine 0.004\n",
            "             egypt 0.005\n",
            "               the 0.000\n",
            "          greatest 0.017\n",
            "          oriental 0.001\n",
            "             movie 0.001\n",
            "             maker 0.006\n",
            "               has 0.002\n",
            "        compassion 0.003\n",
            "               for 0.000\n",
            "          everyone 0.010\n",
            "               for 0.000\n",
            "                an 0.000\n",
            "                us 0.005\n",
            "           soldier 0.001\n",
            "               who 0.002\n",
            "              died 0.001\n",
            "               ten 0.001\n",
            "             years 0.008\n",
            "               ago 0.004\n",
            "               for 0.000\n",
            "               the 0.000\n",
            "            people 0.000\n",
            "                in 0.000\n",
            "               the 0.000\n",
            "               wtc 0.017\n",
            "               but 0.000\n",
            "              also 0.002\n",
            "               for 0.000\n",
            "                 a 0.000\n",
            "       palestinian 0.001\n",
            "           suicide 0.003\n",
            "         terrorist 0.001\n",
            "             maybe 0.001\n",
            "               the 0.000\n",
            "              less 0.001\n",
            "            tender 0.001\n",
            "             movie 0.001\n",
            "           towards 0.002\n",
            "               the 0.000\n",
            "                us 0.005\n",
            "             <unk> 0.002\n",
            "             <unk> 0.002\n",
            "            bosnia 0.004\n",
            "             <unk> 0.002\n",
            "              good 0.004\n",
            "            images 0.004\n",
            "             makes 0.001\n",
            "                us 0.005\n",
            "            travel 0.009\n",
            "               for 0.000\n",
            "              sure 0.000\n",
            "               not 0.003\n",
            "                 a 0.000\n",
            "              very 0.004\n",
            "              good 0.004\n",
            "              plot 0.003\n",
            "           idrissa 0.001\n",
            "             <unk> 0.002\n",
            "             <unk> 0.002\n",
            "             <unk> 0.002\n",
            "              from 0.001\n",
            "               one 0.000\n",
            "                of 0.000\n",
            "               the 0.000\n",
            "           poorest 0.016\n",
            "           country 0.006\n",
            "                in 0.000\n",
            "               the 0.000\n",
            "             world 0.004\n",
            "                 a 0.000\n",
            "            tender 0.001\n",
            "               and 0.000\n",
            "             funny 0.004\n",
            "             story 0.001\n",
            "             about 0.001\n",
            "              five 0.001\n",
            "              boys 0.001\n",
            "               who 0.002\n",
            "              want 0.002\n",
            "                to 0.000\n",
            "           capture 0.001\n",
            "             osama 0.021\n",
            "               bin 0.002\n",
            "             laden 0.000\n",
            "               and 0.000\n",
            "              they 0.000\n",
            "             could 0.003\n",
            "              have 0.001\n",
            "              done 0.001\n",
            "                it 0.002\n",
            "               but 0.000\n",
            "            nobody 0.003\n",
            "          believes 0.001\n",
            "              them 0.002\n",
            "              when 0.000\n",
            "              they 0.000\n",
            "              tell 0.003\n",
            "              they 0.000\n",
            "              know 0.003\n",
            "             where 0.000\n",
            "                he 0.000\n",
            "                is 0.000\n",
            "               ken 0.002\n",
            "             loach 0.002\n",
            "                uk 0.001\n",
            "         september 0.010\n",
            "               the 0.000\n",
            "             chile 0.000\n",
            "           entered 0.002\n",
            "                in 0.000\n",
            "                 a 0.000\n",
            "            twenty 0.000\n",
            "             years 0.008\n",
            "              long 0.001\n",
            "            bloody 0.002\n",
            "             <unk> 0.002\n",
            "         thousands 0.000\n",
            "                of 0.000\n",
            "             death 0.005\n",
            "          tortures 0.002\n",
            "               all 0.003\n",
            "              that 0.000\n",
            "               was 0.000\n",
            "           offered 0.000\n",
            "                to 0.000\n",
            "             chile 0.000\n",
            "                by 0.000\n",
            "             henry 0.000\n",
            "         kissinger 0.001\n",
            "               and 0.000\n",
            "               the 0.000\n",
            "               cia 0.008\n",
            "               and 0.000\n",
            "           knowing 0.010\n",
            "              this 0.001\n",
            "           changes 0.000\n",
            "              very 0.004\n",
            "              much 0.002\n",
            "              your 0.000\n",
            "             point 0.002\n",
            "                of 0.000\n",
            "              view 0.001\n",
            "                 i 0.000\n",
            "             guess 0.004\n",
            "              that 0.000\n",
            "                is 0.000\n",
            "           because 0.002\n",
            "                of 0.000\n",
            "              that 0.000\n",
            "        particular 0.001\n",
            "             short 0.001\n",
            "              that 0.000\n",
            "                no 0.003\n",
            "          american 0.001\n",
            "             movie 0.001\n",
            "      distribution 0.005\n",
            "           company 0.012\n",
            "          accepted 0.000\n",
            "                to 0.000\n",
            "           release 0.008\n",
            "               the 0.000\n",
            "             movie 0.001\n",
            "                in 0.000\n",
            "                us 0.005\n",
            "          theaters 0.000\n",
            "             loach 0.002\n",
            "            forgot 0.001\n",
            "                to 0.000\n",
            "             point 0.002\n",
            "              that 0.000\n",
            "                is 0.000\n",
            "              also 0.002\n",
            "               the 0.000\n",
            "              year 0.001\n",
            "              when 0.000\n",
            "               the 0.000\n",
            "               wtc 0.017\n",
            "               was 0.000\n",
            "             built 0.001\n",
            "         alejandro 0.000\n",
            "          gonzalez 0.000\n",
            "             <unk> 0.002\n",
            "            mexico 0.001\n",
            "        impressing 0.006\n",
            "            images 0.004\n",
            "              that 0.000\n",
            "                we 0.000\n",
            "               all 0.003\n",
            "              know 0.003\n",
            "               too 0.001\n",
            "              well 0.008\n",
            "               and 0.000\n",
            "                 a 0.000\n",
            "               lot 0.002\n",
            "                of 0.000\n",
            "             black 0.000\n",
            "           screens 0.001\n",
            "                 i 0.000\n",
            "             didnt 0.000\n",
            "               get 0.000\n",
            "              this 0.001\n",
            "               one 0.000\n",
            "              very 0.004\n",
            "              much 0.002\n",
            "                it 0.002\n",
            "                is 0.000\n",
            "              more 0.001\n",
            "                an 0.000\n",
            "            artist 0.002\n",
            "             video 0.000\n",
            "                to 0.000\n",
            "              show 0.001\n",
            "                in 0.000\n",
            "                an 0.000\n",
            "        exhibition 0.002\n",
            "              than 0.001\n",
            "                 a 0.000\n",
            "             movie 0.001\n",
            "              amos 0.000\n",
            "             <unk> 0.002\n",
            "             <unk> 0.002\n",
            "                an 0.000\n",
            "            absurd 0.003\n",
            "            ballet 0.001\n",
            "                of 0.000\n",
            "         policemen 0.001\n",
            "       journalists 0.000\n",
            "               etc 0.000\n",
            "            around 0.001\n",
            "                 a 0.000\n",
            "           burning 0.005\n",
            "               car 0.000\n",
            "                in 0.000\n",
            "         jerusalem 0.002\n",
            "              very 0.004\n",
            "              well 0.008\n",
            "              done 0.001\n",
            "              mira 0.002\n",
            "              nair 0.000\n",
            "             india 0.005\n",
            "             about 0.001\n",
            "               the 0.000\n",
            "              anti 0.001\n",
            "           islamic 0.006\n",
            "           feeling 0.000\n",
            "              that 0.000\n",
            "          followed 0.000\n",
            "         september 0.010\n",
            "               the 0.000\n",
            "                th 0.001\n",
            "              very 0.004\n",
            "              good 0.004\n",
            "             <unk> 0.002\n",
            "              sean 0.000\n",
            "              penn 0.001\n",
            "                us 0.005\n",
            "                 a 0.000\n",
            "             funny 0.004\n",
            "            little 0.001\n",
            "             story 0.001\n",
            "              that 0.000\n",
            "           reminds 0.000\n",
            "                us 0.005\n",
            "                 a 0.000\n",
            "              fact 0.000\n",
            "             <unk> 0.002\n",
            "         forgotten 0.004\n",
            "               the 0.000\n",
            "               wtc 0.017\n",
            "               did 0.001\n",
            "              have 0.001\n",
            "                 a 0.000\n",
            "              huge 0.001\n",
            "            shadow 0.000\n",
            "               and 0.000\n",
            "              some 0.001\n",
            "            places 0.000\n",
            "               now 0.001\n",
            "              have 0.001\n",
            "                 a 0.000\n",
            "          daylight 0.001\n",
            "              they 0.000\n",
            "             never 0.000\n",
            "               had 0.004\n",
            "            shohei 0.024\n",
            "           imamura 0.001\n",
            "             japan 0.001\n",
            "                 a 0.000\n",
            "         different 0.008\n",
            "               one 0.000\n",
            "              here 0.001\n",
            "             there 0.000\n",
            "                is 0.000\n",
            "               not 0.003\n",
            "              even 0.003\n",
            "               one 0.000\n",
            "              word 0.000\n",
            "             about 0.001\n",
            "               the 0.000\n",
            "               wtc 0.017\n",
            "               and 0.000\n",
            "               the 0.000\n",
            "            action 0.001\n",
            "             takes 0.004\n",
            "             place 0.000\n",
            "                at 0.000\n",
            "               the 0.000\n",
            "               end 0.004\n",
            "                of 0.000\n",
            "              wwii 0.001\n",
            "                it 0.002\n",
            "               has 0.002\n",
            "              only 0.000\n",
            "               one 0.000\n",
            "           message 0.000\n",
            "                no 0.003\n",
            "               war 0.004\n",
            "                is 0.000\n",
            "              holy 0.001\n",
            "              this 0.001\n",
            "             short 0.001\n",
            "             movie 0.001\n",
            "             gives 0.003\n",
            "              very 0.004\n",
            "              deep 0.002\n",
            "          feelings 0.000\n",
            "               but 0.000\n",
            "               the 0.000\n",
            "          director 0.000\n",
            "             <unk> 0.002\n",
            "             would 0.004\n",
            "              have 0.001\n",
            "              done 0.001\n",
            "            better 0.004\n",
            "              with 0.000\n",
            "              more 0.001\n",
            "              than 0.001\n",
            "           minutes 0.010\n",
            "                so 0.000\n",
            "                 a 0.000\n",
            "             great 0.008\n",
            "             movie 0.001\n",
            "                 a 0.000\n",
            "             great 0.008\n",
            "           attempt 0.010\n",
            "                to 0.000\n",
            "              take 0.001\n",
            "               the 0.000\n",
            "            worlds 0.001\n",
            "       temperature 0.010\n",
            "                 i 0.000\n",
            "              love 0.009\n",
            "                it 0.002\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "             <pad> 0.000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that high weights are assigned to emotional words like *excellent* or *boring* which is expected. But sometimes relatively high weights are also assigned to rather neutral words like *wtc* which is rather surprising. This occurs when such a neutral word appears only in positive or negative training reviews. Then the model thinks that it is important. This is one cause of the mentioned overfitting."
      ],
      "metadata": {
        "id": "6Pg_7IACUcae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head attention"
      ],
      "metadata": {
        "id": "X3AmiDL_xKY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would expect that the attention mechanism assigns low weights to neutral words and high weights to strongly emotional words both negative and positive. But the energies or scalar products are high for words with embedding features similar to the query vector. It is hard to expect that the query vector can be similar to features of both negative and positive words. Maybe there should be two query vectors and two sets of attention weights. This observation leads to the idea of multi-head attention that we will now implement. Start with the hitherto query-key-value attention:"
      ],
      "metadata": {
        "id": "eXitFxe8xOlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "    def forward(self, feature):                         #(samples, frames, features)\n",
        "        key = feature @ self.weightK                    #(samples, frames, features)\n",
        "        value = feature @ self.weightV                  #(samples, frames, features)\n",
        "        energy = self.query @ key.transpose(1, 2)       #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2) #(samples, 1, frames)\n",
        "        feature = weight @ value                        #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "eqXNV3HJzR5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ordinary matrix-multiplication operator is not sufficient to implement multi-head attention. So first rewrite the same attention module in terms of tensor product and Einstein summation:"
      ],
      "metadata": {
        "id": "eekMZrGDzW8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "    def forward(self, feature):                                #(samples, frames, features)\n",
        "        key = torch.tensordot(feature, self.weightK, 1)        #(samples, frames, features)\n",
        "        value = torch.tensordot(feature, self.weightV, 1)      #(samples, frames, features)\n",
        "        energy = torch.einsum('ijk,ilk->ijl', self.query, key) #(samples, 1, frames)\n",
        "        weight = torch.nn.functional.softmax(energy, 2)        #(samples, 1, frames)\n",
        "        feature = torch.einsum('ijk,ikl->ijl', weight, value)  #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "jNz4BsXN0Y-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In principle a multi-head attention is just a set of several attention modules each with its own parameters. Each of these modules is called a head and there may be arbitrarily many heads. For our purposes set the number of heads to two:"
      ],
      "metadata": {
        "id": "jd7DBgpT1R4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heads = 2"
      ],
      "metadata": {
        "id": "-8qDCvX42bSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of using many attention modules we will add a `heads` dimension to each tensor in one module:"
      ],
      "metadata": {
        "id": "exLmC2Cl2c4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features, heads))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "    def forward(self, feature):                                   #(samples, frames, features)\n",
        "        key = torch.tensordot(feature, self.weightK, 1)           #(samples, frames, features, heads)\n",
        "        value = torch.tensordot(feature, self.weightV, 1)         #(samples, frames, features, heads)\n",
        "        energy = torch.einsum('ijkm,ilkm->ijlm', self.query, key) #(samples, 1, frames, heads)\n",
        "        weight = torch.nn.functional.softmax(energy, 2)           #(samples, 1, frames, heads)\n",
        "        feature = torch.einsum('ijkm,iklm->ijlm', weight, value)  #(samples, 1, features, heads)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "YzLvMX6R0ySf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each head gives a set of output features that must be somehow aggregated back to one set. It can be done by just averaging the features over the heads:"
      ],
      "metadata": {
        "id": "R6w6-VQS4Ifz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features, heads))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "    def forward(self, feature):                                   #(samples, frames, features)\n",
        "        key = torch.tensordot(feature, self.weightK, 1)           #(samples, frames, features, heads)\n",
        "        value = torch.tensordot(feature, self.weightV, 1)         #(samples, frames, features, heads)\n",
        "        energy = torch.einsum('ijkm,ilkm->ijlm', self.query, key) #(samples, 1, frames, heads)\n",
        "        weight = torch.nn.functional.softmax(energy, 2)           #(samples, 1, frames, heads)\n",
        "        feature = torch.einsum('ijkm,iklm->ijlm', weight, value)  #(samples, 1, features, heads)\n",
        "        feature = feature.mean(3)                                 #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "D3NpEJnQyZAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A better way is to catenate the features from all heads and then pass them through a linear layer that will again produce one set of features:"
      ],
      "metadata": {
        "id": "C64IXy1kyaap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features, heads))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "        self.linear = torch.nn.Linear(features * heads, features)\n",
        "    def forward(self, feature):                                   #(samples, frames, features)\n",
        "        key = torch.tensordot(feature, self.weightK, 1)           #(samples, frames, features, heads)\n",
        "        value = torch.tensordot(feature, self.weightV, 1)         #(samples, frames, features, heads)\n",
        "        energy = torch.einsum('ijkm,ilkm->ijlm', self.query, key) #(samples, 1, frames, heads)\n",
        "        weight = torch.nn.functional.softmax(energy, 2)           #(samples, 1, frames, heads)\n",
        "        feature = torch.einsum('ijkm,iklm->ijlm', weight, value)  #(samples, 1, features, heads)\n",
        "        feature = feature.flatten(2)                              #(samples, 1, features * heads)\n",
        "        feature = self.linear(feature)                            #(samples, 1, features)\n",
        "        return feature"
      ],
      "metadata": {
        "id": "xyyiFZBZ0_AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final output from this multi-head attention has the same shape as previously. So substitute this attention into the previous model:"
      ],
      "metadata": {
        "id": "3SsE7kkF5q7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):             #(samples, frames)\n",
        "        feature = self.encoder(index)     #(samples, frames, features)\n",
        "        feature = self.attention(feature) #(samples, 1, features)\n",
        "        logit = self.classifier(feature)  #(samples, 1, 1)\n",
        "        logit = logit.flatten()           #(samples)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "7oswWhLG6Aa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate the model:"
      ],
      "metadata": {
        "id": "RytJBKei55dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().cuda()"
      ],
      "metadata": {
        "id": "saW7E-4Z6LPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train it:"
      ],
      "metadata": {
        "id": "ZZOygU3J6OpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = list()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "max_valid_accuracy = torch.tensor(0.).cuda()\n",
        "for epoch in range(128):\n",
        "    valid_accuracy = torch.tensor(0).cuda()\n",
        "    samples = torch.tensor(0).cuda()\n",
        "    for truth_label, index in valid_pipe:\n",
        "        truth_label, index = truth_label.cuda(), index.cuda()\n",
        "        logit = model(index)\n",
        "        model_label = logit.gt(0).float()\n",
        "        hit = model_label.eq(truth_label)\n",
        "        valid_accuracy += hit.count_nonzero()\n",
        "        samples += hit.numel()\n",
        "    valid_accuracy = valid_accuracy / samples\n",
        "    if max_valid_accuracy.lt(valid_accuracy):\n",
        "        max_valid_accuracy = valid_accuracy\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    train_accuracy = torch.tensor(0).cuda()\n",
        "    samples = torch.tensor(0).cuda()\n",
        "    for truth_label, index in train_pipe:\n",
        "        truth_label, index = truth_label.cuda(), index.cuda()\n",
        "        logit = model(index)\n",
        "        model_label = logit.gt(0).float()\n",
        "        hit = model_label.eq(truth_label)\n",
        "        train_accuracy += hit.count_nonzero()\n",
        "        samples += hit.numel()\n",
        "        loss = torch.nn.functional.binary_cross_entropy_with_logits(logit, truth_label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_accuracy = train_accuracy / samples\n",
        "    history.append((epoch, train_accuracy.item(), valid_accuracy.item()))\n",
        "    print('%5i %5.3f %5.3f' % (epoch, train_accuracy, valid_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uDw5ktr36bvp",
        "outputId": "34e7c8c7-cc9d-4d42-ca07-87c148cb13ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0 0.542 0.507\n",
            "    1 0.750 0.636\n",
            "    2 0.841 0.806\n",
            "    3 0.867 0.844\n",
            "    4 0.882 0.859\n",
            "    5 0.895 0.868\n",
            "    6 0.903 0.874\n",
            "    7 0.910 0.878\n",
            "    8 0.917 0.883\n",
            "    9 0.923 0.883\n",
            "   10 0.927 0.887\n",
            "   11 0.933 0.884\n",
            "   12 0.936 0.887\n",
            "   13 0.941 0.888\n",
            "   14 0.945 0.890\n",
            "   15 0.951 0.890\n",
            "   16 0.954 0.889\n",
            "   17 0.958 0.890\n",
            "   18 0.961 0.890\n",
            "   19 0.965 0.886\n",
            "   20 0.969 0.887\n",
            "   21 0.972 0.882\n",
            "   22 0.975 0.883\n",
            "   23 0.977 0.883\n",
            "   24 0.980 0.882\n",
            "   25 0.983 0.881\n",
            "   26 0.986 0.877\n",
            "   27 0.987 0.878\n",
            "   28 0.989 0.876\n",
            "   29 0.990 0.876\n",
            "   30 0.992 0.873\n",
            "   31 0.993 0.872\n",
            "   32 0.995 0.869\n",
            "   33 0.996 0.869\n",
            "   34 0.997 0.866\n",
            "   35 0.998 0.866\n",
            "   36 0.998 0.863\n",
            "   37 0.999 0.862\n",
            "   38 0.999 0.860\n",
            "   39 0.999 0.859\n",
            "   40 0.999 0.859\n",
            "   41 1.000 0.856\n",
            "   42 0.999 0.854\n",
            "   43 1.000 0.856\n",
            "   44 1.000 0.854\n",
            "   45 1.000 0.854\n",
            "   46 1.000 0.854\n",
            "   47 1.000 0.854\n",
            "   48 1.000 0.854\n",
            "   49 1.000 0.854\n",
            "   50 1.000 0.853\n",
            "   51 1.000 0.850\n",
            "   52 1.000 0.853\n",
            "   53 1.000 0.854\n",
            "   54 1.000 0.853\n",
            "   55 1.000 0.853\n",
            "   56 1.000 0.854\n",
            "   57 1.000 0.854\n",
            "   58 1.000 0.853\n",
            "   59 1.000 0.853\n",
            "   60 1.000 0.853\n",
            "   61 1.000 0.853\n",
            "   62 1.000 0.851\n",
            "   63 1.000 0.851\n",
            "   64 1.000 0.851\n",
            "   65 1.000 0.850\n",
            "   66 1.000 0.851\n",
            "   67 1.000 0.851\n",
            "   68 1.000 0.851\n",
            "   69 1.000 0.850\n",
            "   70 1.000 0.851\n",
            "   71 1.000 0.854\n",
            "   72 1.000 0.852\n",
            "   73 1.000 0.852\n",
            "   74 1.000 0.852\n",
            "   75 1.000 0.852\n",
            "   76 1.000 0.851\n",
            "   77 1.000 0.852\n",
            "   78 1.000 0.851\n",
            "   79 1.000 0.851\n",
            "   80 1.000 0.851\n",
            "   81 1.000 0.851\n",
            "   82 1.000 0.849\n",
            "   83 1.000 0.850\n",
            "   84 1.000 0.849\n",
            "   85 1.000 0.850\n",
            "   86 1.000 0.850\n",
            "   87 1.000 0.849\n",
            "   88 1.000 0.850\n",
            "   89 1.000 0.850\n",
            "   90 1.000 0.849\n",
            "   91 1.000 0.852\n",
            "   92 1.000 0.853\n",
            "   93 1.000 0.852\n",
            "   94 1.000 0.851\n",
            "   95 1.000 0.851\n",
            "   96 1.000 0.851\n",
            "   97 1.000 0.851\n",
            "   98 1.000 0.852\n",
            "   99 1.000 0.851\n",
            "  100 1.000 0.851\n",
            "  101 1.000 0.850\n",
            "  102 1.000 0.850\n",
            "  103 1.000 0.850\n",
            "  104 1.000 0.850\n",
            "  105 1.000 0.850\n",
            "  106 1.000 0.850\n",
            "  107 1.000 0.850\n",
            "  108 1.000 0.850\n",
            "  109 1.000 0.850\n",
            "  110 1.000 0.850\n",
            "  111 1.000 0.850\n",
            "  112 1.000 0.849\n",
            "  113 1.000 0.850\n",
            "  114 1.000 0.850\n",
            "  115 1.000 0.850\n",
            "  116 1.000 0.854\n",
            "  117 1.000 0.852\n",
            "  118 1.000 0.852\n",
            "  119 1.000 0.853\n",
            "  120 1.000 0.853\n",
            "  121 1.000 0.853\n",
            "  122 1.000 0.853\n",
            "  123 1.000 0.853\n",
            "  124 1.000 0.853\n",
            "  125 1.000 0.853\n",
            "  126 1.000 0.854\n",
            "  127 1.000 0.853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the accuracies:"
      ],
      "metadata": {
        "id": "T480t6UV6iGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch, train_accuracy, valid_accuracy = zip(*history)\n",
        "\n",
        "plt.grid()\n",
        "plt.plot(epoch, train_accuracy)\n",
        "plt.plot(epoch, valid_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Uo2G-6Hh6kO_",
        "outputId": "424d2b7e-0a86-4c2b-f627-034dc4066d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fded8dc4d30>]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validation accuracy with two-head attention seems slightly higher than with one-head attention. To inspect the weights create an attention module that returns them as previously:"
      ],
      "metadata": {
        "id": "C0_mWuAX-45D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.query = torch.nn.Parameter(torch.empty(1, 1, features, heads))\n",
        "        self.weightK = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        self.weightV = torch.nn.Parameter(torch.empty(features, features, heads))\n",
        "        torch.nn.init.xavier_normal_(self.query)\n",
        "        torch.nn.init.xavier_normal_(self.weightK)\n",
        "        torch.nn.init.xavier_normal_(self.weightV)\n",
        "        self.linear = torch.nn.Linear(features * heads, features)\n",
        "    def forward(self, feature):                                   #(samples, frames, features)\n",
        "        key = torch.tensordot(feature, self.weightK, 1)           #(samples, frames, features, heads)\n",
        "        value = torch.tensordot(feature, self.weightV, 1)         #(samples, frames, features, heads)\n",
        "        energy = torch.einsum('ijkm,ilkm->ijlm', self.query, key) #(samples, 1, frames, heads)\n",
        "        weight = torch.nn.functional.softmax(energy, 2)           #(samples, 1, frames, heads)\n",
        "        feature = torch.einsum('ijkm,iklm->ijlm', weight, value)  #(samples, 1, features, heads)\n",
        "        feature = feature.flatten(2)                              #(samples, 1, features * heads)\n",
        "        feature = self.linear(feature)                            #(samples, 1, features)\n",
        "        return feature, weight"
      ],
      "metadata": {
        "id": "vvO0KvRQ_Bbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the corresponding model:"
      ],
      "metadata": {
        "id": "3vWFMikGFHfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        torch.nn.Module.__init__(self)\n",
        "        self.encoder = torch.nn.Embedding(indices, features)\n",
        "        self.attention = Attention()\n",
        "        self.classifier = torch.nn.Linear(features, 1)\n",
        "    def forward(self, index):                     #(samples, frames)\n",
        "        feature = self.encoder(index)             #(samples, frames, features)\n",
        "        feature, weight = self.attention(feature) #(samples, 1, features)\n",
        "        logit = self.classifier(feature)          #(samples, 1, 1)\n",
        "        logit = logit.flatten()                   #(samples)\n",
        "        return logit, weight"
      ],
      "metadata": {
        "id": "wuQM5AKk_EZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate the model and load the best parameters:"
      ],
      "metadata": {
        "id": "SDLI7pY5FKj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "metadata": {
        "id": "PN8ZMQZ9_n6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate through some batches of the validation data. From each batch take the first sample and display the words together with their weights assigned by the attention mechanism:"
      ],
      "metadata": {
        "id": "Brb06VJfFXh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for truth_label1, index2 in valid_pipe.header(10):\n",
        "    colab.output.clear()\n",
        "    logit1, weight3 = model(index2)\n",
        "    for index0, weight1 in zip(index2[0], weight3[0, 0]):\n",
        "        print('%18s %5.3f %5.3f' % (itos[index0], weight1[0], weight1[1]))\n",
        "    input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rtw6jED0_0hJ",
        "outputId": "9c71e01b-09a7-4a56-ffad-6c1d344ed6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                as 0.001 0.001\n",
            "               you 0.005 0.007\n",
            "               may 0.000 0.000\n",
            "              know 0.000 0.000\n",
            "               the 0.000 0.001\n",
            "           subject 0.002 0.000\n",
            "              here 0.000 0.001\n",
            "               was 0.000 0.002\n",
            "                to 0.001 0.001\n",
            "               ask 0.000 0.001\n",
            "            eleven 0.003 0.000\n",
            "         directors 0.001 0.010\n",
            "              from 0.000 0.000\n",
            "               all 0.001 0.000\n",
            "              over 0.001 0.003\n",
            "               the 0.000 0.001\n",
            "             world 0.004 0.001\n",
            "                to 0.001 0.001\n",
            "              make 0.003 0.005\n",
            "              each 0.000 0.000\n",
            "                 a 0.001 0.000\n",
            "             short 0.001 0.002\n",
            "             movie 0.000 0.000\n",
            "                of 0.001 0.002\n",
            "           minutes 0.000 0.020\n",
            "           seconds 0.001 0.000\n",
            "               and 0.000 0.001\n",
            "               one 0.001 0.001\n",
            "             frame 0.001 0.000\n",
            "                we 0.002 0.000\n",
            "              have 0.002 0.002\n",
            "              here 0.000 0.001\n",
            "             <unk> 0.001 0.000\n",
            "             <unk> 0.001 0.000\n",
            "              iran 0.001 0.002\n",
            "              what 0.001 0.000\n",
            "            afghan 0.000 0.014\n",
            "           refugee 0.003 0.001\n",
            "              kids 0.001 0.003\n",
            "               can 0.003 0.002\n",
            "        understand 0.001 0.003\n",
            "                to 0.001 0.001\n",
            "               the 0.000 0.001\n",
            "            towers 0.003 0.000\n",
            "        collapsing 0.000 0.013\n",
            "              well 0.006 0.000\n",
            "           nothing 0.006 0.001\n",
            "                 a 0.001 0.000\n",
            "             great 0.014 0.003\n",
            "            lesson 0.001 0.000\n",
            "            claude 0.000 0.001\n",
            "           lelouch 0.002 0.000\n",
            "            france 0.001 0.031\n",
            "                 a 0.001 0.000\n",
            "              weak 0.009 0.000\n",
            "              plot 0.000 0.009\n",
            "              with 0.001 0.003\n",
            "                 a 0.001 0.000\n",
            "             great 0.014 0.003\n",
            "    cinematography 0.001 0.000\n",
            "              just 0.002 0.000\n",
            "           imagine 0.001 0.000\n",
            "                 a 0.001 0.000\n",
            "              deaf 0.001 0.001\n",
            "             woman 0.003 0.000\n",
            "            living 0.001 0.010\n",
            "                by 0.001 0.012\n",
            "               the 0.000 0.001\n",
            "               wtc 0.006 0.001\n",
            "               who 0.003 0.000\n",
            "              sees 0.001 0.001\n",
            "           without 0.001 0.001\n",
            "     understanding 0.001 0.001\n",
            "                it 0.002 0.002\n",
            "              that 0.000 0.000\n",
            "               her 0.000 0.000\n",
            "               dog 0.002 0.000\n",
            "             barks 0.007 0.000\n",
            "              well 0.006 0.000\n",
            "              just 0.002 0.000\n",
            "               see 0.005 0.002\n",
            "                it 0.002 0.002\n",
            "           youssef 0.025 0.000\n",
            "           chahine 0.004 0.001\n",
            "             egypt 0.008 0.002\n",
            "               the 0.000 0.001\n",
            "          greatest 0.011 0.000\n",
            "          oriental 0.000 0.000\n",
            "             movie 0.000 0.000\n",
            "             maker 0.010 0.004\n",
            "               has 0.001 0.002\n",
            "        compassion 0.003 0.004\n",
            "               for 0.000 0.000\n",
            "          everyone 0.003 0.000\n",
            "               for 0.000 0.000\n",
            "                an 0.000 0.001\n",
            "                us 0.001 0.003\n",
            "           soldier 0.005 0.000\n",
            "               who 0.003 0.000\n",
            "              died 0.002 0.011\n",
            "               ten 0.003 0.000\n",
            "             years 0.002 0.003\n",
            "               ago 0.008 0.000\n",
            "               for 0.000 0.000\n",
            "               the 0.000 0.001\n",
            "            people 0.005 0.001\n",
            "                in 0.001 0.000\n",
            "               the 0.000 0.001\n",
            "               wtc 0.006 0.001\n",
            "               but 0.001 0.000\n",
            "              also 0.001 0.001\n",
            "               for 0.000 0.000\n",
            "                 a 0.001 0.000\n",
            "       palestinian 0.001 0.000\n",
            "           suicide 0.001 0.000\n",
            "         terrorist 0.001 0.000\n",
            "             maybe 0.000 0.012\n",
            "               the 0.000 0.001\n",
            "              less 0.002 0.001\n",
            "            tender 0.002 0.000\n",
            "             movie 0.000 0.000\n",
            "           towards 0.000 0.007\n",
            "               the 0.000 0.001\n",
            "                us 0.001 0.003\n",
            "             <unk> 0.001 0.000\n",
            "             <unk> 0.001 0.000\n",
            "            bosnia 0.000 0.002\n",
            "             <unk> 0.001 0.000\n",
            "              good 0.003 0.002\n",
            "            images 0.004 0.000\n",
            "             makes 0.004 0.001\n",
            "                us 0.001 0.003\n",
            "            travel 0.002 0.001\n",
            "               for 0.000 0.000\n",
            "              sure 0.004 0.000\n",
            "               not 0.002 0.000\n",
            "                 a 0.001 0.000\n",
            "              very 0.002 0.000\n",
            "              good 0.003 0.002\n",
            "              plot 0.000 0.009\n",
            "           idrissa 0.001 0.000\n",
            "             <unk> 0.001 0.000\n",
            "             <unk> 0.001 0.000\n",
            "             <unk> 0.001 0.000\n",
            "              from 0.000 0.000\n",
            "               one 0.001 0.001\n",
            "                of 0.001 0.002\n",
            "               the 0.000 0.001\n",
            "           poorest 0.001 0.065\n",
            "           country 0.001 0.004\n",
            "                in 0.001 0.000\n",
            "               the 0.000 0.001\n",
            "             world 0.004 0.001\n",
            "                 a 0.001 0.000\n",
            "            tender 0.002 0.000\n",
            "               and 0.000 0.001\n",
            "             funny 0.001 0.000\n",
            "             story 0.000 0.001\n",
            "             about 0.001 0.001\n",
            "              five 0.001 0.000\n",
            "              boys 0.001 0.001\n",
            "               who 0.003 0.000\n",
            "              want 0.001 0.000\n",
            "                to 0.001 0.001\n",
            "           capture 0.001 0.001\n",
            "             osama 0.005 0.000\n",
            "               bin 0.003 0.002\n",
            "             laden 0.003 0.000\n",
            "               and 0.000 0.001\n",
            "              they 0.001 0.001\n",
            "             could 0.000 0.006\n",
            "              have 0.002 0.002\n",
            "              done 0.000 0.002\n",
            "                it 0.002 0.002\n",
            "               but 0.001 0.000\n",
            "            nobody 0.001 0.003\n",
            "          believes 0.001 0.000\n",
            "              them 0.000 0.001\n",
            "              when 0.002 0.000\n",
            "              they 0.001 0.001\n",
            "              tell 0.000 0.005\n",
            "              they 0.001 0.001\n",
            "              know 0.000 0.000\n",
            "             where 0.001 0.000\n",
            "                he 0.003 0.001\n",
            "                is 0.002 0.000\n",
            "               ken 0.015 0.000\n",
            "             loach 0.001 0.000\n",
            "                uk 0.001 0.000\n",
            "         september 0.003 0.028\n",
            "               the 0.000 0.001\n",
            "             chile 0.001 0.000\n",
            "           entered 0.004 0.003\n",
            "                in 0.001 0.000\n",
            "                 a 0.001 0.000\n",
            "            twenty 0.000 0.016\n",
            "             years 0.002 0.003\n",
            "              long 0.000 0.003\n",
            "            bloody 0.001 0.002\n",
            "             <unk> 0.001 0.000\n",
            "         thousands 0.000 0.008\n",
            "                of 0.001 0.002\n",
            "             death 0.005 0.000\n",
            "          tortures 0.002 0.000\n",
            "               all 0.001 0.000\n",
            "              that 0.000 0.000\n",
            "               was 0.000 0.002\n",
            "           offered 0.004 0.000\n",
            "                to 0.001 0.001\n",
            "             chile 0.001 0.000\n",
            "                by 0.001 0.012\n",
            "             henry 0.001 0.001\n",
            "         kissinger 0.000 0.008\n",
            "               and 0.000 0.001\n",
            "               the 0.000 0.001\n",
            "               cia 0.001 0.000\n",
            "               and 0.000 0.001\n",
            "           knowing 0.014 0.001\n",
            "              this 0.001 0.000\n",
            "           changes 0.003 0.000\n",
            "              very 0.002 0.000\n",
            "              much 0.001 0.000\n",
            "              your 0.002 0.000\n",
            "             point 0.012 0.004\n",
            "                of 0.001 0.002\n",
            "              view 0.003 0.000\n",
            "                 i 0.001 0.000\n",
            "             guess 0.001 0.018\n",
            "              that 0.000 0.000\n",
            "                is 0.002 0.000\n",
            "           because 0.002 0.000\n",
            "                of 0.001 0.002\n",
            "              that 0.000 0.000\n",
            "        particular 0.000 0.024\n",
            "             short 0.001 0.002\n",
            "              that 0.000 0.000\n",
            "                no 0.014 0.000\n",
            "          american 0.001 0.000\n",
            "             movie 0.000 0.000\n",
            "      distribution 0.001 0.000\n",
            "           company 0.001 0.002\n",
            "          accepted 0.000 0.001\n",
            "                to 0.001 0.001\n",
            "           release 0.000 0.036\n",
            "               the 0.000 0.001\n",
            "             movie 0.000 0.000\n",
            "                in 0.001 0.000\n",
            "                us 0.001 0.003\n",
            "          theaters 0.001 0.008\n",
            "             loach 0.001 0.000\n",
            "            forgot 0.001 0.000\n",
            "                to 0.001 0.001\n",
            "             point 0.012 0.004\n",
            "              that 0.000 0.000\n",
            "                is 0.002 0.000\n",
            "              also 0.001 0.001\n",
            "               the 0.000 0.001\n",
            "              year 0.003 0.000\n",
            "              when 0.002 0.000\n",
            "               the 0.000 0.001\n",
            "               wtc 0.006 0.001\n",
            "               was 0.000 0.002\n",
            "             built 0.005 0.011\n",
            "         alejandro 0.001 0.001\n",
            "          gonzalez 0.004 0.000\n",
            "             <unk> 0.001 0.000\n",
            "            mexico 0.001 0.001\n",
            "        impressing 0.000 0.005\n",
            "            images 0.004 0.000\n",
            "              that 0.000 0.000\n",
            "                we 0.002 0.000\n",
            "               all 0.001 0.000\n",
            "              know 0.000 0.000\n",
            "               too 0.008 0.000\n",
            "              well 0.006 0.000\n",
            "               and 0.000 0.001\n",
            "                 a 0.001 0.000\n",
            "               lot 0.004 0.004\n",
            "                of 0.001 0.002\n",
            "             black 0.002 0.001\n",
            "           screens 0.001 0.000\n",
            "                 i 0.001 0.000\n",
            "             didnt 0.000 0.010\n",
            "               get 0.003 0.000\n",
            "              this 0.001 0.000\n",
            "               one 0.001 0.001\n",
            "              very 0.002 0.000\n",
            "              much 0.001 0.000\n",
            "                it 0.002 0.002\n",
            "                is 0.002 0.000\n",
            "              more 0.000 0.001\n",
            "                an 0.000 0.001\n",
            "            artist 0.001 0.001\n",
            "             video 0.004 0.000\n",
            "                to 0.001 0.001\n",
            "              show 0.000 0.002\n",
            "                in 0.001 0.000\n",
            "                an 0.000 0.001\n",
            "        exhibition 0.000 0.000\n",
            "              than 0.000 0.000\n",
            "                 a 0.001 0.000\n",
            "             movie 0.000 0.000\n",
            "              amos 0.005 0.003\n",
            "             <unk> 0.001 0.000\n",
            "             <unk> 0.001 0.000\n",
            "                an 0.000 0.001\n",
            "            absurd 0.006 0.000\n",
            "            ballet 0.000 0.000\n",
            "                of 0.001 0.002\n",
            "         policemen 0.000 0.001\n",
            "       journalists 0.000 0.001\n",
            "               etc 0.001 0.000\n",
            "            around 0.001 0.000\n",
            "                 a 0.001 0.000\n",
            "           burning 0.000 0.008\n",
            "               car 0.002 0.001\n",
            "                in 0.001 0.000\n",
            "         jerusalem 0.000 0.001\n",
            "              very 0.002 0.000\n",
            "              well 0.006 0.000\n",
            "              done 0.000 0.002\n",
            "              mira 0.002 0.002\n",
            "              nair 0.000 0.001\n",
            "             india 0.003 0.004\n",
            "             about 0.001 0.001\n",
            "               the 0.000 0.001\n",
            "              anti 0.006 0.000\n",
            "           islamic 0.001 0.001\n",
            "           feeling 0.001 0.000\n",
            "              that 0.000 0.000\n",
            "          followed 0.001 0.000\n",
            "         september 0.003 0.028\n",
            "               the 0.000 0.001\n",
            "                th 0.001 0.000\n",
            "              very 0.002 0.000\n",
            "              good 0.003 0.002\n",
            "             <unk> 0.001 0.000\n",
            "              sean 0.001 0.000\n",
            "              penn 0.003 0.000\n",
            "                us 0.001 0.003\n",
            "                 a 0.001 0.000\n",
            "             funny 0.001 0.000\n",
            "            little 0.002 0.001\n",
            "             story 0.000 0.001\n",
            "              that 0.000 0.000\n",
            "           reminds 0.010 0.000\n",
            "                us 0.001 0.003\n",
            "                 a 0.001 0.000\n",
            "              fact 0.001 0.000\n",
            "             <unk> 0.001 0.000\n",
            "         forgotten 0.000 0.000\n",
            "               the 0.000 0.001\n",
            "               wtc 0.006 0.001\n",
            "               did 0.000 0.000\n",
            "              have 0.002 0.002\n",
            "                 a 0.001 0.000\n",
            "              huge 0.002 0.003\n",
            "            shadow 0.002 0.001\n",
            "               and 0.000 0.001\n",
            "              some 0.004 0.000\n",
            "            places 0.001 0.001\n",
            "               now 0.008 0.000\n",
            "              have 0.002 0.002\n",
            "                 a 0.001 0.000\n",
            "          daylight 0.003 0.000\n",
            "              they 0.001 0.001\n",
            "             never 0.002 0.002\n",
            "               had 0.001 0.000\n",
            "            shohei 0.015 0.001\n",
            "           imamura 0.015 0.000\n",
            "             japan 0.008 0.000\n",
            "                 a 0.001 0.000\n",
            "         different 0.005 0.000\n",
            "               one 0.001 0.001\n",
            "              here 0.000 0.001\n",
            "             there 0.001 0.000\n",
            "                is 0.002 0.000\n",
            "               not 0.002 0.000\n",
            "              even 0.001 0.004\n",
            "               one 0.001 0.001\n",
            "              word 0.000 0.000\n",
            "             about 0.001 0.001\n",
            "               the 0.000 0.001\n",
            "               wtc 0.006 0.001\n",
            "               and 0.000 0.001\n",
            "               the 0.000 0.001\n",
            "            action 0.007 0.000\n",
            "             takes 0.003 0.000\n",
            "             place 0.001 0.000\n",
            "                at 0.001 0.001\n",
            "               the 0.000 0.001\n",
            "               end 0.000 0.000\n",
            "                of 0.001 0.002\n",
            "              wwii 0.001 0.000\n",
            "                it 0.002 0.002\n",
            "               has 0.001 0.002\n",
            "              only 0.000 0.004\n",
            "               one 0.001 0.001\n",
            "           message 0.002 0.002\n",
            "                no 0.014 0.000\n",
            "               war 0.004 0.006\n",
            "                is 0.002 0.000\n",
            "              holy 0.001 0.004\n",
            "              this 0.001 0.000\n",
            "             short 0.001 0.002\n",
            "             movie 0.000 0.000\n",
            "             gives 0.001 0.000\n",
            "              very 0.002 0.000\n",
            "              deep 0.003 0.000\n",
            "          feelings 0.009 0.000\n",
            "               but 0.001 0.000\n",
            "               the 0.000 0.001\n",
            "          director 0.000 0.014\n",
            "             <unk> 0.001 0.000\n",
            "             would 0.005 0.000\n",
            "              have 0.002 0.002\n",
            "              done 0.000 0.002\n",
            "            better 0.001 0.000\n",
            "              with 0.001 0.003\n",
            "              more 0.000 0.001\n",
            "              than 0.000 0.000\n",
            "           minutes 0.000 0.020\n",
            "                so 0.000 0.002\n",
            "                 a 0.001 0.000\n",
            "             great 0.014 0.003\n",
            "             movie 0.000 0.000\n",
            "                 a 0.001 0.000\n",
            "             great 0.014 0.003\n",
            "           attempt 0.005 0.000\n",
            "                to 0.001 0.001\n",
            "              take 0.001 0.000\n",
            "               the 0.000 0.001\n",
            "            worlds 0.003 0.002\n",
            "       temperature 0.000 0.002\n",
            "                 i 0.001 0.000\n",
            "              love 0.001 0.016\n",
            "                it 0.002 0.002\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "             <pad> 0.000 0.000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is hard to say whether the two attention heads indeed respond to negative and positive words but at least they have learned something different and thus enriched the model. Now proceed to the next notebook to replace attention with self-attention and introduce the transformer architecture."
      ],
      "metadata": {
        "id": "6fB6J51rFc4n"
      }
    }
  ]
}